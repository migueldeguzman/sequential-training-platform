{
  "project": "Energy Profiler for ML Dashboard",
  "description": "Comprehensive energy and power profiling system for transformer inference on Apple Silicon M4 Max",
  "version": "2.0.0",
  "created": "2026-01-13",
  "updated": "2026-01-13",
  "hardware": {
    "target": "Apple Silicon M4 Max 128GB",
    "power_source": "powermetrics with sudo (sudoers entry for passwordless access)",
    "sampling_interval_ms": 100
  },
  "architecture": {
    "backend": {
      "framework": "FastAPI",
      "components": [
        "PowerMonitor - wraps powermetrics, samples CPU/GPU/ANE/DRAM power",
        "LayerProfiler - PyTorch hooks on all transformer components",
        "DeepAttentionProfiler - lowest-level tensor operation profiling",
        "InferencePipelineProfiler - full start-to-finish section accounting",
        "ProfileDatabase - SQLite storage with prompt-centric schema",
        "WebSocket streaming for real-time profiling data"
      ],
      "new_endpoints": [
        "/api/profiling/generate",
        "/api/profiling/runs",
        "/api/profiling/run/{id}",
        "/api/profiling/run/{id}/summary",
        "/api/profiling/run/{id}/pipeline",
        "/api/profiling/export/{id}",
        "/ws/profiling"
      ]
    },
    "frontend": {
      "framework": "React/Next.js",
      "chart_libraries": {
        "heatmaps": "Custom Canvas (performance for large grids)",
        "time_series": "Custom Canvas (real-time streaming)",
        "treemap": "D3.js (hierarchical layouts)",
        "sankey": "D3-sankey (flow diagrams)"
      },
      "components": [
        "EnergyProfilerPanel - main container",
        "ProfilingControls - start/stop, model select",
        "RealTimeView - live during inference",
        "AnalysisView - post-inference exploration",
        "HistoryBrowser - past runs and comparison"
      ]
    },
    "database": {
      "type": "SQLite",
      "path": "backend/profiling.db"
    }
  },
  "inference_pipeline_sections": {
    "description": "Complete start-to-finish energy accounting by section",
    "phases": {
      "pre_inference": {
        "sections": [
          "tokenization - tokenizer.encode()",
          "tensor_transfer - input to device",
          "kv_cache_init - initialize key-value cache"
        ]
      },
      "prefill": {
        "description": "Process entire prompt in one forward pass",
        "sections": [
          "embedding_lookup - token embeddings",
          "position_embedding - positional encoding",
          "layers - all transformer layers (see layer_components)",
          "final_layernorm - output normalization",
          "lm_head - projection to vocabulary",
          "kv_cache_store - save keys/values for decode"
        ]
      },
      "decode": {
        "description": "Generate tokens one at a time",
        "per_token_sections": [
          "embedding - previous token embedding",
          "position - position encoding for new position",
          "layers - all transformer layers",
          "final_layernorm - output normalization",
          "lm_head - projection to vocabulary logits",
          "sampling - temperature, top_k, top_p, sample/argmax",
          "kv_cache_append - add new key/value to cache"
        ]
      },
      "post_inference": {
        "sections": [
          "tensor_to_cpu - move output tensors",
          "detokenization - tokenizer.decode()",
          "cleanup - memory release"
        ]
      }
    }
  },
  "data_model": {
    "hierarchy": "Prompt -> Phases -> Tokens -> Layers -> Components -> Operations",
    "description": "All profiling data clusters under the prompt that generated it"
  },
  "features": [
    {
      "id": "EP-001",
      "title": "Project Setup and Dependencies",
      "description": "Set up project structure and install required dependencies",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Add pynvml, psutil to requirements.txt (power monitoring helpers)",
        "Add d3, d3-sankey to package.json for visualizations",
        "Create backend/profiling/ directory structure",
        "Create src/components/profiling/ directory structure",
        "Create backend/profiling/__init__.py"
      ]
    },
    {
      "id": "EP-002",
      "title": "Sudoers Configuration for powermetrics",
      "description": "Configure passwordless sudo access for powermetrics",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create setup script to add sudoers entry",
        "Add documentation for manual sudoers setup",
        "Add verification check for powermetrics access on backend startup",
        "Add graceful fallback message if powermetrics unavailable"
      ]
    },
    {
      "id": "EP-003",
      "title": "PowerMonitor Class - Basic Implementation",
      "description": "Create PowerMonitor class to spawn and manage powermetrics subprocess",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create backend/profiling/power_monitor.py",
        "Implement PowerMonitor.__init__ with configurable sample interval",
        "Implement PowerMonitor.start() to spawn powermetrics subprocess",
        "Implement PowerMonitor.stop() to terminate subprocess and collect samples",
        "Implement PowerMonitor.is_available() class method to check powermetrics access"
      ]
    },
    {
      "id": "EP-004",
      "title": "PowerMonitor Class - Plist Parsing",
      "description": "Parse powermetrics plist/XML output into structured data",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Implement plist XML parser for powermetrics output",
        "Extract CPU power (per cluster if available)",
        "Extract GPU power",
        "Extract ANE power",
        "Extract DRAM power",
        "Create PowerSample dataclass with all fields",
        "Handle parsing errors gracefully"
      ]
    },
    {
      "id": "EP-005",
      "title": "PowerMonitor Class - Async Sampling Thread",
      "description": "Run power sampling in background thread during inference",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Implement background thread for continuous sampling",
        "Add thread-safe sample collection queue",
        "Implement get_current() for latest sample",
        "Implement get_samples() to retrieve all collected samples",
        "Add proper thread cleanup on stop()"
      ]
    },
    {
      "id": "EP-006",
      "title": "SQLite Database Schema Creation",
      "description": "Create SQLite database with full schema for profiling data",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create backend/profiling/database.py",
        "Define profiling_runs table schema",
        "Define power_samples table schema",
        "Define pipeline_sections table schema",
        "Define tokens table schema",
        "Define layer_metrics table schema",
        "Define component_metrics table schema",
        "Define deep_operation_metrics table schema",
        "Create all indexes for query performance",
        "Implement database initialization function"
      ]
    },
    {
      "id": "EP-007",
      "title": "ProfileDatabase Class - CRUD Operations",
      "description": "Implement database access class with all CRUD operations",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Implement ProfileDatabase.__init__ with connection management",
        "Implement create_run() to insert new profiling run",
        "Implement add_power_samples() with batch insert",
        "Implement add_pipeline_section()",
        "Implement add_token() with metrics",
        "Implement add_layer_metrics() with batch insert",
        "Implement add_component_metrics() with batch insert",
        "Implement add_deep_operation_metrics() with batch insert"
      ]
    },
    {
      "id": "EP-008",
      "title": "ProfileDatabase Class - Query Methods",
      "description": "Implement query methods for retrieving profiling data",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Implement get_run(run_id) for full run data",
        "Implement get_runs() with filtering (date, model, tags)",
        "Implement get_run_summary(run_id) for aggregated stats",
        "Implement get_tokens(run_id) with metrics",
        "Implement get_layer_metrics(token_id)",
        "Implement get_component_metrics(layer_metric_id)",
        "Implement get_power_timeline(run_id)",
        "Implement search_by_prompt(query_string)",
        "Implement delete_run(run_id)"
      ]
    },
    {
      "id": "EP-009",
      "title": "Model Architecture Detector",
      "description": "Auto-detect transformer model architecture for hook registration",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create backend/profiling/model_detector.py",
        "Implement detection for Llama architecture",
        "Implement detection for Mistral architecture",
        "Implement detection for Phi architecture",
        "Implement detection for Qwen architecture",
        "Return standardized component paths for each architecture",
        "Add fallback for unknown architectures with warning"
      ]
    },
    {
      "id": "EP-010",
      "title": "LayerProfiler Class - Hook Registration",
      "description": "Create LayerProfiler to register PyTorch forward hooks on model components",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create backend/profiling/layer_profiler.py",
        "Implement LayerProfiler.__init__ with model reference",
        "Use ModelArchitectureDetector to find component paths",
        "Register hooks on attention components (q_proj, k_proj, v_proj, o_proj)",
        "Register hooks on MLP components (gate_proj, up_proj, down_proj)",
        "Register hooks on layer norms",
        "Store hook handles for later removal"
      ]
    },
    {
      "id": "EP-011",
      "title": "LayerProfiler Class - Timing Capture",
      "description": "Capture accurate timing for each hooked component",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Implement pre-hook to record start time",
        "Implement post-hook to record end time",
        "Use torch.mps.synchronize() before timing on Apple Silicon",
        "Store timing in thread-local storage for concurrent safety",
        "Implement get_timings() to retrieve all component timings",
        "Implement reset() to clear timings between tokens"
      ]
    },
    {
      "id": "EP-012",
      "title": "LayerProfiler Class - Activation Statistics",
      "description": "Capture activation statistics from hook outputs",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Capture activation mean (output.abs().mean())",
        "Capture activation std (output.std())",
        "Capture activation max (output.abs().max())",
        "Capture activation sparsity ((output.abs() < threshold).mean())",
        "Make threshold configurable",
        "Store statistics per component per forward pass"
      ]
    },
    {
      "id": "EP-013",
      "title": "LayerProfiler Class - Cleanup",
      "description": "Implement proper hook removal and cleanup",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Implement detach() to remove all hooks",
        "Implement context manager (__enter__, __exit__)",
        "Ensure hooks are removed even on exceptions",
        "Clear all stored metrics on cleanup"
      ]
    },
    {
      "id": "EP-014",
      "title": "DeepAttentionProfiler - Monkey Patch Approach",
      "description": "Implement deep operation profiling via monkey-patching HuggingFace attention",
      "priority": "HIGH",
      "passes": true,
      "steps": [
        "Create backend/profiling/deep_profiler.py",
        "Store original attention forward method",
        "Create instrumented attention forward wrapper",
        "Time QK^T matmul operation",
        "Time scale operation",
        "Time mask application",
        "Time softmax operation",
        "Time value matmul operation",
        "Implement patch() and unpatch() methods"
      ]
    },
    {
      "id": "EP-015",
      "title": "DeepAttentionProfiler - Extra Metrics",
      "description": "Capture additional attention metrics beyond timing",
      "priority": "HIGH",
      "passes": true,
      "steps": [
        "Compute attention entropy per head",
        "Compute max attention weight per head",
        "Compute attention sparsity (near-zero weights)",
        "Store per-head metrics for analysis",
        "Compute average across heads for summary"
      ]
    },
    {
      "id": "EP-016",
      "title": "DeepAttentionProfiler - MLP Operations",
      "description": "Profile deep operations within MLP blocks",
      "priority": "HIGH",
      "passes": true,
      "steps": [
        "Patch MLP forward method",
        "Time gate projection and activation",
        "Time up projection and activation",
        "Time gate * up multiplication",
        "Time down projection",
        "Compute activation kill ratio (negative inputs to GELU/SiLU)"
      ]
    },
    {
      "id": "EP-017",
      "title": "DeepAttentionProfiler - LayerNorm Operations",
      "description": "Profile deep operations within LayerNorm",
      "priority": "HIGH",
      "passes": true,
      "steps": [
        "Patch LayerNorm forward method",
        "Time mean computation",
        "Time variance computation",
        "Time normalization operation",
        "Time scale and shift (gamma, beta)",
        "Compute input/output variance ratio"
      ]
    },
    {
      "id": "EP-018",
      "title": "DeepAttentionProfiler - Custom Wrapper Approach",
      "description": "Alternative deep profiling via model wrapper",
      "priority": "HIGH",
      "passes": true,
      "steps": [
        "Create InstrumentedModelWrapper class",
        "Override forward to intercept layer calls",
        "Support both monkey-patch and wrapper via config",
        "Add config flag: profiling_depth = 'module' | 'deep'",
        "Document tradeoffs between approaches"
      ]
    },
    {
      "id": "EP-019",
      "title": "InferencePipelineProfiler - Core Structure",
      "description": "Create main profiler orchestrating all components",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create backend/profiling/pipeline_profiler.py",
        "Implement InferencePipelineProfiler.__init__",
        "Accept PowerMonitor, LayerProfiler, DeepProfiler, Database",
        "Create run context manager for profiling session",
        "Generate unique run IDs"
      ]
    },
    {
      "id": "EP-020",
      "title": "InferencePipelineProfiler - Section Timing",
      "description": "Implement section timing context manager",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Create section() context manager",
        "Record section start timestamp",
        "Record section end timestamp",
        "Calculate section duration",
        "Correlate with power samples for energy calculation",
        "Store section data for database"
      ]
    },
    {
      "id": "EP-021",
      "title": "InferencePipelineProfiler - Pre-Inference Phase",
      "description": "Profile pre-inference operations",
      "priority": "CRITICAL",
      "passes": true,
      "steps": [
        "Wrap tokenizer.encode() with section timing",
        "Wrap tensor.to(device) with section timing",
        "Wrap KV-cache initialization with section timing",
        "Store pre-inference metrics"
      ]
    },
    {
      "id": "EP-022",
      "title": "InferencePipelineProfiler - Prefill Phase",
      "description": "Profile prefill phase (prompt processing)",
      "priority": "CRITICAL",
      "passes": false,
      "steps": [
        "Wrap embedding lookup with section timing",
        "Wrap position embedding with section timing",
        "Profile all layers via LayerProfiler during prefill",
        "Wrap final layernorm with section timing",
        "Wrap LM head projection with section timing",
        "Wrap KV-cache storage with section timing",
        "Aggregate prefill metrics"
      ]
    },
    {
      "id": "EP-023",
      "title": "InferencePipelineProfiler - Decode Phase",
      "description": "Profile decode phase (token generation loop)",
      "priority": "CRITICAL",
      "passes": false,
      "steps": [
        "Create per-token profiling within decode loop",
        "Profile embedding lookup per token",
        "Profile position embedding per token",
        "Capture layer metrics via hooks per token",
        "Profile LM head per token",
        "Profile sampling operation per token",
        "Profile KV-cache append per token",
        "Reset LayerProfiler between tokens"
      ]
    },
    {
      "id": "EP-024",
      "title": "InferencePipelineProfiler - Post-Inference Phase",
      "description": "Profile post-inference operations",
      "priority": "CRITICAL",
      "passes": false,
      "steps": [
        "Wrap tensor.to('cpu') with section timing",
        "Wrap tokenizer.decode() with section timing",
        "Profile memory cleanup if applicable",
        "Calculate total inference energy"
      ]
    },
    {
      "id": "EP-025",
      "title": "InferencePipelineProfiler - Data Aggregation",
      "description": "Aggregate all profiling data for storage",
      "priority": "CRITICAL",
      "passes": false,
      "steps": [
        "Collect all power samples from PowerMonitor",
        "Collect all section timings",
        "Collect all token metrics with layer breakdowns",
        "Collect all component metrics",
        "Collect deep operation metrics if enabled",
        "Calculate energy per section (power * time)",
        "Build complete run data structure"
      ]
    },
    {
      "id": "EP-026",
      "title": "InferencePipelineProfiler - Database Save",
      "description": "Save complete profiling run to database",
      "priority": "CRITICAL",
      "passes": false,
      "steps": [
        "Create profiling_runs record",
        "Batch insert power_samples",
        "Insert pipeline_sections",
        "Insert tokens with metrics",
        "Batch insert layer_metrics",
        "Batch insert component_metrics",
        "Batch insert deep_operation_metrics if present",
        "Return run_id for reference"
      ]
    },
    {
      "id": "EP-027",
      "title": "Profiled Generate Endpoint",
      "description": "Create FastAPI endpoint for profiled inference",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create ProfiledGenerateRequest Pydantic model",
        "Add profiling_depth field (module/deep)",
        "Add tags field for categorization",
        "Add experiment_name field",
        "Implement POST /api/profiling/generate endpoint",
        "Instantiate all profiler components",
        "Run inference with profiling",
        "Save to database and return run_id"
      ]
    },
    {
      "id": "EP-028",
      "title": "Profiling Runs List Endpoint",
      "description": "Create endpoint to list profiling runs",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement GET /api/profiling/runs endpoint",
        "Add query params: model, date_from, date_to, tags, experiment",
        "Add pagination support (limit, offset)",
        "Add sorting options (date, duration, energy)",
        "Return list with summary metrics per run"
      ]
    },
    {
      "id": "EP-029",
      "title": "Profiling Run Detail Endpoint",
      "description": "Create endpoint to get full profiling run data",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement GET /api/profiling/run/{id} endpoint",
        "Include all power samples",
        "Include all pipeline sections",
        "Include all tokens with layer metrics",
        "Include component metrics nested under layers",
        "Include deep operation metrics if present"
      ]
    },
    {
      "id": "EP-030",
      "title": "Profiling Run Summary Endpoint",
      "description": "Create endpoint for aggregated run statistics",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement GET /api/profiling/run/{id}/summary endpoint",
        "Calculate total duration and energy",
        "Calculate per-phase breakdown (pre, prefill, decode, post)",
        "Calculate average metrics per layer",
        "Calculate average metrics per component",
        "Identify hottest components"
      ]
    },
    {
      "id": "EP-031",
      "title": "Profiling Pipeline Breakdown Endpoint",
      "description": "Create endpoint for pipeline section analysis",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement GET /api/profiling/run/{id}/pipeline endpoint",
        "Return hierarchical phase > section breakdown",
        "Include timing and energy per section",
        "Calculate percentage of total per section"
      ]
    },
    {
      "id": "EP-032",
      "title": "Profiling Export Endpoint",
      "description": "Create endpoint to export profiling data",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement GET /api/profiling/export/{id} endpoint",
        "Add format query param (json/csv)",
        "Generate JSON export with full nested structure",
        "Generate CSV export with flattened tables",
        "Set appropriate Content-Type headers",
        "Add Content-Disposition for download"
      ]
    },
    {
      "id": "EP-033",
      "title": "Profiling Delete Endpoint",
      "description": "Create endpoint to delete profiling runs",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement DELETE /api/profiling/run/{id} endpoint",
        "Cascade delete all related records",
        "Return success confirmation"
      ]
    },
    {
      "id": "EP-034",
      "title": "WebSocket Profiling Endpoint - Setup",
      "description": "Create WebSocket endpoint for real-time streaming",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Implement /ws/profiling WebSocket endpoint",
        "Handle client connection/disconnection",
        "Create message queue for profiling events",
        "Define message types enum"
      ]
    },
    {
      "id": "EP-035",
      "title": "WebSocket Profiling - Power Streaming",
      "description": "Stream power samples via WebSocket",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create power_sample message type",
        "Stream samples at 100ms intervals during inference",
        "Include CPU, GPU, ANE, DRAM, total power",
        "Include timestamp relative to inference start"
      ]
    },
    {
      "id": "EP-036",
      "title": "WebSocket Profiling - Section Events",
      "description": "Stream section start/end events",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create section_start message type",
        "Create section_end message type",
        "Include phase, section name, timestamp",
        "Include duration and energy on section_end"
      ]
    },
    {
      "id": "EP-037",
      "title": "WebSocket Profiling - Token Events",
      "description": "Stream token generation events",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create token_complete message type",
        "Include token position and text",
        "Include token duration and energy",
        "Include power snapshot at token time",
        "Include layer metrics summary"
      ]
    },
    {
      "id": "EP-038",
      "title": "WebSocket Profiling - Layer/Component Events",
      "description": "Stream detailed layer and component metrics",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create layer_metrics message type",
        "Create component_metrics message type",
        "Stream after each token if client requests detail",
        "Include full activation statistics"
      ]
    },
    {
      "id": "EP-039",
      "title": "WebSocket Profiling - Inference Complete",
      "description": "Stream final summary on inference completion",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create inference_complete message type",
        "Include run_id for database reference",
        "Include total duration and energy",
        "Include token count and tokens/second",
        "Include summary statistics"
      ]
    },
    {
      "id": "EP-040",
      "title": "Frontend - TypeScript Types",
      "description": "Define TypeScript types for profiling data",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Add ProfilingRun interface to src/types/index.ts",
        "Add PowerSample interface",
        "Add PipelineSection interface",
        "Add TokenMetrics interface",
        "Add LayerMetrics interface",
        "Add ComponentMetrics interface",
        "Add DeepOperationMetrics interface",
        "Add WebSocket message types"
      ]
    },
    {
      "id": "EP-041",
      "title": "Frontend - API Client Extensions",
      "description": "Add profiling API methods to api.ts",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Add profiledGenerate() method",
        "Add getProfilingRuns() method with filters",
        "Add getProfilingRun(id) method",
        "Add getProfilingRunSummary(id) method",
        "Add getProfilingPipeline(id) method",
        "Add exportProfilingRun(id, format) method",
        "Add deleteProfilingRun(id) method"
      ]
    },
    {
      "id": "EP-042",
      "title": "Frontend - Profiling WebSocket Manager",
      "description": "Create WebSocket manager for profiling stream",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/lib/profilingWebsocket.ts",
        "Implement connection management",
        "Parse incoming message types",
        "Emit typed events for each message type",
        "Handle reconnection logic",
        "Provide React hook useProfilingWebSocket()"
      ]
    },
    {
      "id": "EP-043",
      "title": "Frontend - ProfilingContext",
      "description": "Create React context for profiling state",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/ProfilingContext.tsx",
        "Store current profiling run state",
        "Store real-time power samples array",
        "Store real-time token stream",
        "Store current section info",
        "Provide actions: startProfiling, stopProfiling",
        "Connect to WebSocket on profiling start"
      ]
    },
    {
      "id": "EP-044",
      "title": "Frontend - EnergyProfilerPanel Container",
      "description": "Create main Energy Profiler panel component",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/EnergyProfilerPanel.tsx",
        "Add panel header with title",
        "Add tab navigation (Live / Analysis / History)",
        "Wrap with ProfilingContext.Provider",
        "Handle panel state (which view is active)"
      ]
    },
    {
      "id": "EP-045",
      "title": "Frontend - ProfilingControls Component",
      "description": "Create profiling start/stop controls",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/ProfilingControls.tsx",
        "Add model selector dropdown",
        "Add prompt input (or link to existing prompt)",
        "Add profiling depth selector (Module/Deep)",
        "Add tags input",
        "Add Start Profiling button",
        "Add Stop button (during profiling)",
        "Show current status indicator"
      ]
    },
    {
      "id": "EP-046",
      "title": "Frontend - PowerTimeSeriesChart Component",
      "description": "Create real-time power time series visualization",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/PowerTimeSeriesChart.tsx",
        "Use Canvas for performance",
        "Plot CPU power line (blue)",
        "Plot GPU power line (green)",
        "Plot ANE power line (orange)",
        "Plot DRAM power line (purple)",
        "Plot Total power line (red)",
        "Add legend",
        "Update smoothly with new samples",
        "Auto-scroll as time progresses"
      ]
    },
    {
      "id": "EP-047",
      "title": "Frontend - LiveLayerHeatmap Component",
      "description": "Create real-time layer heatmap updating per token",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/LiveLayerHeatmap.tsx",
        "Use Canvas for performance",
        "Y-axis: layers (0 to N)",
        "X-axis: components (q_proj, k_proj, etc.)",
        "Color intensity: selected metric",
        "Update on each token_complete event",
        "Add color scale legend"
      ]
    },
    {
      "id": "EP-048",
      "title": "Frontend - TokenGenerationStream Component",
      "description": "Create live token stream display",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/TokenGenerationStream.tsx",
        "Show tokens as they generate",
        "Color-code by energy consumption",
        "Show timing per token on hover",
        "Auto-scroll to latest token",
        "Show total tokens and tokens/second"
      ]
    },
    {
      "id": "EP-049",
      "title": "Frontend - CurrentOperationIndicator Component",
      "description": "Show current operation being profiled",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/CurrentOperationIndicator.tsx",
        "Show current phase (pre/prefill/decode/post)",
        "Show current section within phase",
        "Show current layer (during layer processing)",
        "Show current component (during component processing)",
        "Animate transitions between operations"
      ]
    },
    {
      "id": "EP-050",
      "title": "Frontend - RealTimeView Container",
      "description": "Compose real-time view with all live components",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/RealTimeView.tsx",
        "Layout: Controls at top",
        "Layout: PowerTimeSeriesChart main area",
        "Layout: LiveLayerHeatmap below",
        "Layout: TokenGenerationStream sidebar",
        "Layout: CurrentOperationIndicator footer",
        "Handle responsive layout"
      ]
    },
    {
      "id": "EP-051",
      "title": "Frontend - MetricSelector Component",
      "description": "Create metric selection dropdown for analysis views",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/MetricSelector.tsx",
        "Options: Time (ms)",
        "Options: Energy (mJ)",
        "Options: Power (mW)",
        "Options: Activation Mean",
        "Options: Activation Max",
        "Options: Sparsity",
        "Options: Attention Entropy (if deep profiling)",
        "Emit selection change event"
      ]
    },
    {
      "id": "EP-052",
      "title": "Frontend - HeatmapChart Component",
      "description": "Create static heatmap for analysis view",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/HeatmapChart.tsx",
        "Accept data array, xLabels, yLabels props",
        "Use Canvas for rendering",
        "Add color scale with configurable gradient",
        "Show value on cell hover",
        "Support click handler for drill-down",
        "Add axis labels"
      ]
    },
    {
      "id": "EP-053",
      "title": "Frontend - TokenSlider Component",
      "description": "Create slider to scrub through tokens",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/TokenSlider.tsx",
        "Range slider from 0 to total tokens",
        "Show token text at current position",
        "Show token metrics at current position",
        "Support play/pause for animation",
        "Emit token index change event"
      ]
    },
    {
      "id": "EP-054",
      "title": "Frontend - PipelineTimeline Component",
      "description": "Create horizontal timeline of inference phases",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/PipelineTimeline.tsx",
        "Show pre_inference, prefill, decode, post_inference as bars",
        "Width proportional to duration",
        "Color by energy consumption",
        "Click to expand section details",
        "Show percentage labels"
      ]
    },
    {
      "id": "EP-055",
      "title": "Frontend - TreemapChart Component",
      "description": "Create hierarchical treemap visualization",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/TreemapChart.tsx",
        "Use D3.js treemap layout",
        "Accept hierarchical data structure",
        "Size rectangles by selected metric",
        "Color by metric or category",
        "Click to zoom into children",
        "Breadcrumb navigation",
        "Show labels with percentage"
      ]
    },
    {
      "id": "EP-056",
      "title": "Frontend - SankeyChart Component",
      "description": "Create Sankey flow diagram",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/SankeyChart.tsx",
        "Use D3-sankey library",
        "Define nodes: Input, Layers, Output",
        "Define links with flow values (energy)",
        "Show attention vs MLP split per layer",
        "Highlight path on hover",
        "Add node labels"
      ]
    },
    {
      "id": "EP-057",
      "title": "Frontend - WaterfallChart Component",
      "description": "Create token waterfall chart",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/charts/WaterfallChart.tsx",
        "Each column = one token",
        "Stacked bars showing component breakdown",
        "Add cumulative energy line overlay",
        "Hover shows token details",
        "Support horizontal scroll for many tokens"
      ]
    },
    {
      "id": "EP-058",
      "title": "Frontend - DeepDrilldown Component",
      "description": "Create detailed view for deep operation metrics",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/DeepDrilldown.tsx",
        "Show when component is clicked in heatmap",
        "Display all deep operations for that component",
        "Show attention entropy, sparsity metrics",
        "Show MLP activation kill ratio",
        "Show LayerNorm variance ratio",
        "Close button to return to overview"
      ]
    },
    {
      "id": "EP-059",
      "title": "Frontend - AnalysisView Container",
      "description": "Compose analysis view with all post-inference components",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Create src/components/profiling/AnalysisView.tsx",
        "Layout: MetricSelector at top",
        "Layout: PipelineTimeline overview",
        "Layout: TokenSlider for token navigation",
        "Layout: HeatmapChart main area",
        "Layout: TreemapChart and SankeyChart tabs",
        "Layout: DeepDrilldown modal",
        "Handle metric selection state"
      ]
    },
    {
      "id": "EP-060",
      "title": "Frontend - RunList Component",
      "description": "Create list of past profiling runs",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/RunList.tsx",
        "Fetch runs from API with pagination",
        "Show: date, model, prompt preview, duration, energy",
        "Add search by prompt text",
        "Add filter by date range",
        "Add filter by model",
        "Add filter by tags",
        "Add sort options",
        "Click to view run details"
      ]
    },
    {
      "id": "EP-061",
      "title": "Frontend - RunDetail Component",
      "description": "Create detailed view for a selected run",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/RunDetail.tsx",
        "Fetch full run data from API",
        "Show run metadata (date, model, prompt, tags)",
        "Embed AnalysisView with run data",
        "Add export buttons (JSON, CSV)",
        "Add delete button with confirmation"
      ]
    },
    {
      "id": "EP-062",
      "title": "Frontend - CompareView Component",
      "description": "Create side-by-side comparison of multiple runs",
      "priority": "LOW",
      "passes": false,
      "steps": [
        "Create src/components/profiling/CompareView.tsx",
        "Allow selecting 2-4 runs to compare",
        "Show metrics side by side",
        "Highlight differences",
        "Show overlay charts for direct comparison",
        "Calculate statistical differences"
      ]
    },
    {
      "id": "EP-063",
      "title": "Frontend - HistoryBrowser Container",
      "description": "Compose history browser with list. detail, and compare",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Create src/components/profiling/HistoryBrowser.tsx",
        "Layout: RunList on left",
        "Layout: RunDetail or CompareView on right",
        "Handle run selection state",
        "Handle compare mode toggle"
      ]
    },
    {
      "id": "EP-064",
      "title": "Frontend - Navigation Integration",
      "description": "Add Energy Profiler to main dashboard navigation",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Add Energy Profiler tab to main page.tsx",
        "Add icon for the tab",
        "Handle tab switching state",
        "Lazy load EnergyProfilerPanel component"
      ]
    },
    {
      "id": "EP-065",
      "title": "Backend - Error Handling",
      "description": "Add comprehensive error handling to profiling system",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Handle powermetrics permission errors gracefully",
        "Handle model loading errors during profiled inference",
        "Handle database write errors",
        "Handle WebSocket disconnection during profiling",
        "Return meaningful error messages to frontend",
        "Log errors for debugging"
      ]
    },
    {
      "id": "EP-066",
      "title": "Backend - Performance Optimization",
      "description": "Minimize profiling overhead",
      "priority": "HIGH",
      "passes": false,
      "steps": [
        "Profile the profiler to identify bottlenecks",
        "Use batch database inserts",
        "Minimize tensor copies for activation stats",
        "Use efficient data structures for metric storage",
        "Add option to disable deep profiling for speed",
        "Document overhead percentages"
      ]
    },
    {
      "id": "EP-067",
      "title": "Backend - Data Retention Policies",
      "description": "Add ability to manage profiling data retention",
      "priority": "LOW",
      "passes": false,
      "steps": [
        "Add config for max runs to keep",
        "Add config for max age of runs",
        "Implement cleanup job to remove old runs",
        "Add manual cleanup endpoint",
        "Add database size reporting"
      ]
    },
    {
      "id": "EP-068",
      "title": "Documentation - Setup Guide",
      "description": "Document Energy Profiler setup and usage",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Document sudoers configuration steps",
        "Document backend startup with profiling enabled",
        "Document frontend profiling panel usage",
        "Document interpretation of metrics",
        "Add troubleshooting section"
      ]
    },
    {
      "id": "EP-069",
      "title": "Testing - PowerMonitor Unit Tests",
      "description": "Add unit tests for PowerMonitor class",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Test plist parsing with sample data",
        "Test start/stop lifecycle",
        "Test sample collection",
        "Mock powermetrics subprocess for CI",
        "Test error handling"
      ]
    },
    {
      "id": "EP-070",
      "title": "Testing - LayerProfiler Unit Tests",
      "description": "Add unit tests for LayerProfiler class",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Test hook registration on mock model",
        "Test timing capture",
        "Test activation stats calculation",
        "Test hook cleanup",
        "Test context manager behavior"
      ]
    },
    {
      "id": "EP-071",
      "title": "Testing - Database Unit Tests",
      "description": "Add unit tests for ProfileDatabase class",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Test schema creation",
        "Test CRUD operations",
        "Test query methods",
        "Test batch inserts",
        "Test cascading deletes"
      ]
    },
    {
      "id": "EP-072",
      "title": "Testing - Integration Tests",
      "description": "Add end-to-end integration tests",
      "priority": "MEDIUM",
      "passes": false,
      "steps": [
        "Test full profiled inference with small model",
        "Test data flow from profiler to database",
        "Test API endpoints return correct data",
        "Test WebSocket streaming",
        "Test export functionality"
      ]
    },
    {
      "id": "EP-073",
      "title": "Testing - Frontend Component Tests",
      "description": "Add tests for React profiling components",
      "priority": "LOW",
      "passes": false,
      "steps": [
        "Test EnergyProfilerPanel rendering",
        "Test ProfilingControls interactions",
        "Test chart components with mock data",
        "Test WebSocket hook behavior",
        "Test context state management"
      ]
    },
    {
      "id": "EP-074",
      "title": "Model Architecture Feature Extraction",
      "description": "Extract and store model architectural features for energy analysis (inspired by Caravaca et al. 2025)",
      "priority": "HIGH",
      "passes": false,
      "reference": "Paper: 'From Prompts to Power' - model structure significantly impacts energy beyond parameter count",
      "steps": [
        "Create backend/profiling/model_features.py",
        "Extract num_layers from model config",
        "Extract hidden_size (model dimension)",
        "Extract intermediate_size (FFN dimension)",
        "Extract num_attention_heads",
        "Extract num_key_value_heads (for GQA/MQA detection)",
        "Calculate embedding_params count",
        "Calculate attention_params count per layer",
        "Calculate ffn_params count per layer",
        "Detect attention mechanism type (MHA/GQA/MQA)",
        "Detect if model is MoE (Mixture of Experts)",
        "Store features in profiling_runs table"
      ]
    },
    {
      "id": "EP-075",
      "title": "Prefill vs Decode Energy Analysis",
      "description": "Separate tracking and analysis of prefill vs decode phase energy (paper shows output tokens ~11x more costly than input)",
      "priority": "HIGH",
      "passes": false,
      "reference": "Paper finding: Output tokens consume 11x more energy than input tokens for same count",
      "steps": [
        "Track total energy for prefill phase separately",
        "Track total energy for decode phase separately",
        "Calculate energy per input token (prefill_energy / input_tokens)",
        "Calculate energy per output token (decode_energy / output_tokens)",
        "Calculate input/output token energy ratio",
        "Store prefill_energy_mj and decode_energy_mj in tokens table",
        "Add comparison view in frontend showing input vs output costs"
      ]
    },
    {
      "id": "EP-076",
      "title": "Energy Efficiency Metrics Dashboard",
      "description": "Calculate and display key energy efficiency metrics per run",
      "priority": "HIGH",
      "passes": false,
      "reference": "Paper uses: Wh per prompt, energy per token, normalized by model size",
      "steps": [
        "Calculate total_energy_per_token (mJ/token)",
        "Calculate prefill_energy_per_token",
        "Calculate decode_energy_per_token",
        "Calculate energy_per_million_params",
        "Calculate tokens_per_joule (efficiency score)",
        "Calculate power_utilization_percentage (actual vs TDP if available)",
        "Add efficiency metrics to run summary API",
        "Create EfficiencyMetricsCard frontend component"
      ]
    },
    {
      "id": "EP-077",
      "title": "Model Comparison View",
      "description": "Compare energy profiles across different models and configurations",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "Paper Figure 4: Same parameter count can have order-of-magnitude energy differences",
      "steps": [
        "Create /api/profiling/compare endpoint",
        "Accept list of run_ids to compare",
        "Normalize metrics by prompt length for fair comparison",
        "Calculate relative efficiency scores",
        "Create ModelComparisonChart component",
        "Show scatter plot: model_size vs energy",
        "Show bar chart: energy per token by model",
        "Highlight outliers (unusually efficient/inefficient)"
      ]
    },
    {
      "id": "EP-078",
      "title": "Architectural Impact Analysis",
      "description": "Analyze how model architecture affects energy consumption",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "Paper finding: Layers scale linearly, dimensionality scales quadratically with energy",
      "steps": [
        "Create ArchitecturalAnalysis component",
        "Plot energy vs num_layers (expect linear relationship)",
        "Plot energy vs hidden_size (expect quadratic relationship)",
        "Plot energy vs intermediate_size",
        "Compare MHA vs GQA vs MQA energy profiles",
        "Show correlation coefficients for each architectural feature",
        "Add regression line overlays"
      ]
    },
    {
      "id": "EP-079",
      "title": "Energy Prediction Model",
      "description": "Build ML model to predict energy consumption before running inference",
      "priority": "LOW",
      "passes": false,
      "reference": "Paper achieves RÂ²=0.92-0.98 with Random Forest using architectural + prompt features",
      "steps": [
        "Create backend/profiling/energy_predictor.py",
        "Collect training data from profiling runs",
        "Feature engineering: model features + prompt features",
        "Train Random Forest or XGBoost model",
        "Implement predict_energy(model_config, input_tokens, output_tokens)",
        "Add /api/profiling/predict endpoint",
        "Create EnergyPredictionWidget frontend component",
        "Show predicted vs actual comparison after runs"
      ]
    },
    {
      "id": "EP-080",
      "title": "Long Context Energy Analysis",
      "description": "Track how context length affects energy consumption and KV cache pressure",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "Paper Figure 2: Long context significantly increases energy, KV cache is bottleneck",
      "steps": [
        "Track KV cache memory usage per run",
        "Calculate KV cache utilization percentage",
        "Plot energy vs input_token_count for long prompts",
        "Identify KV cache saturation point",
        "Warn when approaching memory limits",
        "Create LongContextAnalysis component"
      ]
    },
    {
      "id": "EP-081",
      "title": "Quantization Energy Comparison",
      "description": "Compare energy consumption across different quantization levels",
      "priority": "LOW",
      "passes": false,
      "reference": "Paper Figure 8: Quantization significantly reduces energy in memory-constrained scenarios",
      "steps": [
        "Detect model precision (FP32, FP16, BF16, FP8, INT8, INT4)",
        "Store precision in model features",
        "Create comparison view for same model at different precisions",
        "Show energy savings from quantization",
        "Note: Apple Silicon may behave differently than NVIDIA GPUs"
      ]
    },
    {
      "id": "EP-082",
      "title": "Token-Level Energy Visualization",
      "description": "Enhanced per-token energy visualization showing patterns",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "Paper analyzes energy per prompt; we go deeper with per-token granularity",
      "steps": [
        "Color-code tokens by energy consumption intensity",
        "Show token energy distribution histogram",
        "Identify high-energy tokens (complex reasoning?)",
        "Identify low-energy tokens (common patterns?)",
        "Create TokenEnergyHeatmap showing token position vs layer",
        "Enable filtering by energy threshold"
      ]
    },
    {
      "id": "EP-083",
      "title": "Apple Silicon vs Paper Comparison Notes",
      "description": "Document differences between our Apple Silicon results and paper's NVIDIA results",
      "priority": "LOW",
      "passes": false,
      "reference": "Paper uses NVIDIA GPUs; we use Apple Silicon M4 Max with unified memory",
      "steps": [
        "Document Apple Silicon power measurement methodology",
        "Note: We measure CPU+GPU+ANE+DRAM (paper measures GPU only ~88%)",
        "Note: Unified memory architecture differences",
        "Note: No CUDA graphs on Apple Silicon (MPS backend)",
        "Create comparison notes in documentation",
        "Track any patterns that differ from paper's findings"
      ]
    },
    {
      "id": "EP-084",
      "title": "Phase-Tagged Power Samples",
      "description": "Tag every power sample with the active inference phase for precise energy attribution",
      "priority": "HIGH",
      "passes": false,
      "reference": "TokenPowerBench: Phase-aligned metrics pipeline attributes energy to prefill/decode stages",
      "steps": [
        "Add 'phase' field to PowerSample dataclass (idle/pre_inference/prefill/decode/post_inference)",
        "Update PowerMonitor to accept current_phase setter",
        "Tag each sample with active phase at collection time",
        "Store phase in power_samples database table",
        "Calculate phase-specific energy: E_prefill = sum(samples where phase=prefill)",
        "Calculate phase-specific energy: E_decode = sum(samples where phase=decode)",
        "Add phase breakdown to run summary API",
        "Color-code power timeline chart by phase"
      ]
    },
    {
      "id": "EP-085",
      "title": "Peak Power Tracking",
      "description": "Track and display peak power draw during inference, not just averages",
      "priority": "HIGH",
      "passes": false,
      "reference": "TokenPowerBench: Reports peak power alongside averages for capacity planning",
      "steps": [
        "Add peak_power_mw field to profiling_runs table",
        "Add peak_power_cpu_mw, peak_power_gpu_mw, peak_power_ane_mw, peak_power_dram_mw",
        "Track peak values during PowerMonitor sampling",
        "Record timestamp of peak power occurrence",
        "Add peak power to run summary API",
        "Show peak vs average comparison in frontend",
        "Add peak power marker on power timeline chart"
      ]
    },
    {
      "id": "EP-086",
      "title": "Idle Power Baseline Measurement",
      "description": "Measure idle power before inference to calculate active power delta",
      "priority": "HIGH",
      "passes": false,
      "reference": "TokenPowerBench: Separates idle from active power for accurate attribution",
      "steps": [
        "Add 2-second idle sampling period before inference start",
        "Calculate baseline_power_mw as average during idle",
        "Store baseline in profiling_runs table",
        "Calculate active_power_delta = measured - baseline",
        "Show idle vs active power comparison",
        "Option to subtract baseline from all measurements",
        "Display baseline on power timeline chart as horizontal line"
      ]
    },
    {
      "id": "EP-087",
      "title": "Batch Size Energy Analysis",
      "description": "Analyze how batch size affects energy per token for throughput optimization",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "TokenPowerBench: 2-3Ã energy spread between batch 32-1024, steepest drop at 32-256",
      "steps": [
        "Add batch_size field to profiling_runs table",
        "Track batch size used during inference",
        "Create endpoint to compare runs with different batch sizes",
        "Plot energy_per_token vs batch_size curve",
        "Identify optimal batch size for energy efficiency",
        "Show throughput (tokens/s) vs energy tradeoff",
        "Create BatchSizeAnalysis frontend component"
      ]
    },
    {
      "id": "EP-088",
      "title": "Energy-Delay Product Metric",
      "description": "Calculate Energy-Delay Product (EDP) for holistic efficiency assessment",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "TokenPowerBench: EDP combines energy and latency into single efficiency metric",
      "steps": [
        "Calculate EDP = total_energy_mj Ã total_duration_ms",
        "Store EDP in profiling_runs table",
        "Calculate EDP per token",
        "Calculate EDP per phase (prefill/decode)",
        "Add EDP to efficiency metrics in run summary",
        "Lower EDP = better (optimizes both energy and speed)",
        "Show EDP comparison across runs"
      ]
    },
    {
      "id": "EP-089",
      "title": "Cost and Carbon Estimation",
      "description": "Estimate electricity cost and CO2 emissions from energy consumption",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "TokenPowerBench: Converts kWh to dollar cost and CO2 for sustainability reporting",
      "steps": [
        "Add settings for electricity_price_per_kwh (default: $0.12)",
        "Add settings for carbon_intensity_g_per_kwh (default: 400g for US grid)",
        "Calculate cost_usd = (energy_mj / 3600000) Ã electricity_price",
        "Calculate co2_grams = (energy_mj / 3600000) Ã carbon_intensity",
        "Store cost and carbon estimates in database",
        "Add cost/carbon to run summary API",
        "Create CostCarbonCard frontend component",
        "Support regional carbon intensity presets (CA, TX, EU, etc.)"
      ]
    },
    {
      "id": "EP-090",
      "title": "Component Energy Breakdown Chart",
      "description": "Visualize energy split across CPU, GPU, ANE, DRAM components",
      "priority": "HIGH",
      "passes": false,
      "reference": "TokenPowerBench: E_total = E_GPU + E_CPU + E_DRAM + E_Others; GPUs ~60% of total",
      "steps": [
        "Calculate total energy per component from phase-tagged samples",
        "Create stacked bar chart showing component breakdown",
        "Show percentage of total per component",
        "Compare component ratios across different runs",
        "Identify which component dominates (GPU expected ~60%)",
        "Show component breakdown per phase",
        "Create ComponentBreakdownChart frontend component"
      ]
    },
    {
      "id": "EP-091",
      "title": "MoE Energy Analysis",
      "description": "Special analysis for Mixture-of-Experts models showing efficiency gains",
      "priority": "LOW",
      "passes": false,
      "reference": "TokenPowerBench: MoE uses 2-3Ã less energy than dense with similar quality",
      "steps": [
        "Detect MoE architecture in model_features",
        "Track number of active experts per token",
        "Calculate effective_params = active_experts Ã expert_params",
        "Compare energy per effective parameter",
        "Show MoE efficiency vs equivalent dense model",
        "Track expert activation patterns over tokens",
        "Create MoEAnalysis frontend component"
      ]
    },
    {
      "id": "EP-092",
      "title": "Energy Scaling Analysis",
      "description": "Analyze super-linear energy scaling with model parameters",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "TokenPowerBench: 1Bâ70B = 7.3Ã energy (not 70Ã) due to memory/cache overhead",
      "steps": [
        "Collect energy data across models of different sizes",
        "Plot energy vs total_params scatter",
        "Fit power-law curve: energy = a Ã params^b",
        "Calculate scaling exponent b (expect b < 1 but super-linear in practice)",
        "Show energy per million parameters metric",
        "Identify scaling efficiency: larger models more/less efficient?",
        "Create EnergyScalingChart frontend component"
      ]
    },
    {
      "id": "EP-093",
      "title": "Joules Per Token Metric Standardization",
      "description": "Standardize on Joules per token (J/t) as primary energy metric",
      "priority": "HIGH",
      "passes": false,
      "reference": "TokenPowerBench: Uses J/t as primary metric; enables cross-model comparison",
      "steps": [
        "Calculate joules_per_token = total_energy_mj / 1000 / total_tokens",
        "Calculate joules_per_input_token (prefill)",
        "Calculate joules_per_output_token (decode)",
        "Add J/t to all summary displays prominently",
        "Use J/t as default sort metric in run list",
        "Show J/t trend over time/runs",
        "Enable filtering runs by J/t range"
      ]
    },
    {
      "id": "EP-094",
      "title": "Power Timeline Phase Annotations",
      "description": "Add phase boundary annotations to power timeline visualization",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "TokenPowerBench Figure 1: Shows clear phase boundaries on power timeline",
      "steps": [
        "Draw vertical lines at phase transitions on power chart",
        "Label each phase region (Pre-Inference, Prefill, Decode, Post)",
        "Show phase duration in milliseconds",
        "Show phase energy in millijoules",
        "Highlight decode phase token boundaries",
        "Add zoom to phase functionality"
      ]
    },
    {
      "id": "EP-095",
      "title": "Inference Engine Comparison Support",
      "description": "Support comparing energy across different inference engines/backends",
      "priority": "LOW",
      "passes": false,
      "reference": "TokenPowerBench: Compares vLLM, TensorRT-LLM, DeepSpeed, Transformers",
      "steps": [
        "Add inference_engine field to profiling_runs table",
        "Auto-detect engine (transformers, mlx, etc.)",
        "Enable filtering runs by engine",
        "Compare same model across engines",
        "Show engine efficiency ranking",
        "Note: On Apple Silicon, options are more limited than NVIDIA"
      ]
    },
    {
      "id": "EP-096",
      "title": "Throughput vs Energy Tradeoff Analysis",
      "description": "Analyze the relationship between throughput (tokens/s) and energy efficiency",
      "priority": "MEDIUM",
      "passes": false,
      "reference": "TokenPowerBench: Shows batching improves both throughput and efficiency up to a point",
      "steps": [
        "Calculate tokens_per_second for each run",
        "Calculate tokens_per_joule (energy efficiency)",
        "Plot throughput vs energy_per_token curve",
        "Identify Pareto-optimal configurations",
        "Show knee of the curve (best tradeoff point)",
        "Create ThroughputEnergyTradeoff frontend component"
      ]
    }
  ]
}
