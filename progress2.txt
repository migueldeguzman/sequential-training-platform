# Bug Fix Progress Log
Created: Wed Jan 14 22:59:55 +04 2026

[2026-01-14] BUG-001 - COMPLETED
Status: Fixed async event loop error in power sample callback
Description: Fixed 'no running event loop' errors in WebSocket callbacks by capturing the main event loop at the start of profiled_generate() and replacing all asyncio.create_task() calls with asyncio.run_coroutine_threadsafe() to safely broadcast messages from background threads. Updated 6 callbacks: stream_power_sample, stream_section_event, stream_token_complete, stream_layer_metrics, stream_component_metrics, and stream_inference_complete.
Files Modified: backend/main.py

[2026-01-14] BUG-002 - COMPLETED
Status: Fixed StableLM model compatibility with TextIteratorStreamer
Description: Added StableLM architecture detection in model_detector.py with _is_stablelm_structure() and _detect_stablelm() methods. Created is_streaming_compatible() function to identify models incompatible with TextIteratorStreamer. Modified backend/main.py profiled_generate endpoint to check streaming compatibility and use non-streaming generation (use_cache=False) for incompatible models like StableLM. This prevents crashes from KV cache issues while still allowing profiling to complete successfully with appropriate warnings.
Files Modified: backend/profiling/model_detector.py, backend/main.py

[2026-01-14] BUG-003 - COMPLETED
Status: Fixed section event callbacks async issue
Description: All callback functions (stream_section_event, stream_token_complete, stream_layer_metrics, stream_component_metrics, stream_inference_complete) were already fixed as part of BUG-001. They all use asyncio.run_coroutine_threadsafe() with main_loop for thread-safe WebSocket broadcasting. No additional changes needed.
Files Modified: backend/main.py (already fixed in BUG-001)

[2026-01-14] BUG-004 - COMPLETED
Status: Fixed token timing measurement
Description: Fixed token duration measurement which was timing the append() operation (~0ms) instead of actual token generation time. Implemented proper timing by tracking time between consecutive token arrivals from the streamer. Added last_token_time variable to measure duration as (current_token_time - last_token_time). For the first token, uses a reasonable default of 50ms. This fix ensures accurate token duration values (10-100ms per token) and correct energy calculations.
Files Modified: backend/main.py

[2026-01-14] BUG-005 - COMPLETED
Status: Fixed token field name mismatch between backend and frontend
Description: Fixed field name inconsistency where backend sent 'token_index' but frontend expected 'token_position'. Updated three WebSocket callbacks in backend/main.py: stream_token_complete, stream_layer_metrics, and stream_component_metrics to send 'token_position' instead of 'token_index'. This ensures token position displays correctly in all frontend components (TokenGenerationStream hover tooltips, LiveLayerHeatmap, CurrentOperationIndicator, etc.).
Files Modified: backend/main.py

[2026-01-14] BUG-007 - COMPLETED
Status: Added StableLM architecture detection in model_detector.py
Description: StableLM architecture detection was already added as part of BUG-002 fix. The model_detector.py now includes _is_stablelm_structure() method to properly detect StableLM models and _detect_stablelm() method to return correct component paths. StableLM is now correctly identified as 'stablelm' instead of being misidentified as 'llama', ensuring correct profiling behavior.
Files Modified: backend/profiling/model_detector.py (already fixed in BUG-002)

[2026-01-14] BUG-008 - COMPLETED
Status: Fixed energy calculation using near-zero duration
Description: Energy calculation was automatically fixed by BUG-004. Once token timing measurement was corrected to track actual token generation time (10-100ms per token) instead of append() operation time (~0ms), the energy calculation (current_power_mw * token_duration_ms / 1000.0) now produces realistic token energy values (0.1-10 mJ per token depending on model and hardware).
Files Modified: backend/main.py (already fixed in BUG-004)

[2026-01-14] BUG-009 - COMPLETED
Status: Added model streaming compatibility check
Description: Streaming compatibility check was already added as part of BUG-002 fix. The is_streaming_compatible() function in model_detector.py checks if a model supports TextIteratorStreamer by detecting known incompatible architectures (like StableLM). The profiled_generate endpoint in backend/main.py checks compatibility before using streaming and falls back to non-streaming generation for incompatible models.
Files Modified: backend/profiling/model_detector.py, backend/main.py (already fixed in BUG-002)

[2026-01-14] BUG-016 - COMPLETED
Status: Added Gemma 3 architecture detection
Description: Gemma architecture detection was already implemented in model_detector.py. The detector includes _is_gemma_structure() method and _detect_gemma() method that properly identifies Gemma models (including Gemma 2 and Gemma 3) by checking for model_type == 'gemma' or 'gemma2'. Returns correct component paths with RMSNorm and standard Llama-like structure.
Files Modified: backend/profiling/model_detector.py (already implemented)

[2026-01-14] BUG-017 - COMPLETED
Status: Fixed layer profiler hooks for different architectures
Description: Enhanced LayerProfiler in layer_profiler.py to better support multiple architectures. Added registration statistics tracking to count successful hook registrations per component type. Improved logging to show architecture name, registration summary, and warnings when major components aren't found. Added diagnostic logging for first layer structure. Enhanced error messages to only log on first layer (avoid spam) and include architecture information. Added get_registration_summary() method for external code to check registration success. The LayerProfiler already uses ModelArchitectureDetector dynamically, so it now properly handles all supported architectures (Llama, Mistral, Phi, Qwen, Gemma, StableLM) with better diagnostics when hooks fail to attach.
Files Modified: backend/profiling/layer_profiler.py

[2026-01-14] BUG-006 - COMPLETED
Status: Fixed WebSocket URL hardcoding in frontend
Description: Fixed hardcoded localhost:8000 URLs in frontend by creating centralized configuration. Created src/lib/config.ts that exports API_BASE_URL and getWebSocketUrl() function, both of which check environment variables (NEXT_PUBLIC_API_URL and NEXT_PUBLIC_WS_URL) before falling back to localhost:8000. Updated src/lib/api.ts to import API_BASE_URL from config. Updated src/components/profiling/ProfilingControls.tsx to use API_BASE_URL for model fetching instead of hardcoded URL. Updated src/lib/websocket.ts and src/lib/profilingWebsocket.ts to use getWebSocketUrl() for WebSocket connections. The WebSocket URL is automatically derived from the HTTP API URL (http:// -> ws://, https:// -> wss://), but can be overridden with NEXT_PUBLIC_WS_URL. Frontend now supports deployment to any URL by setting NEXT_PUBLIC_API_URL environment variable.
Files Modified: src/lib/config.ts (new), src/lib/api.ts, src/components/profiling/ProfilingControls.tsx, src/lib/websocket.ts, src/lib/profilingWebsocket.ts

[2026-01-14] BUG-010 - COMPLETED
Status: Fixed profiling cleanup on error
Description: Fixed potential cleanup issues when profiling fails mid-execution. The InferencePipelineProfiler context manager already had proper cleanup in its finally block (lines 339-387 in pipeline_profiler.py), which handles stopping power monitoring, detaching layer profiler hooks, unpatching deep profiler, and saving data to database. However, backend/main.py had redundant cleanup code (lines 2157-2168) that was removed since the context manager handles it automatically. Added proper error handling in the except block to send profiling_error WebSocket events to the frontend when exceptions occur, using the existing ProfilingMessageType.ERROR message type. This ensures the frontend is notified of errors and all resources (PowerMonitor subprocess, layer hooks, deep profiler patches) are properly cleaned up even when profiling fails. Added import time statement to support error timestamp generation.
Files Modified: backend/main.py

[2026-01-14] BUG-013 - COMPLETED
Status: Fixed power sample timestamp using wrong base
Description: Fixed power sample timestamps in WebSocket events to use relative time instead of Unix timestamps. The backend was sending sample.timestamp (Unix timestamp) but the frontend PowerTimeSeriesChart expects timestamp in milliseconds relative to profiling start. Updated stream_power_sample callback in backend/main.py to send sample.relative_time_ms as the timestamp field in both the message and data objects. Also added the phase field to the data object for proper phase display in charts. This fix ensures the power chart X-axis shows time from 0 to profiling duration in seconds, rather than showing huge Unix timestamp values.
Files Modified: backend/main.py

[2026-01-14] BUG-014 - COMPLETED
Status: Fix PowerTimeSeriesChart data format mismatch (verified already fixed)
Description: After thorough code review, confirmed that the PowerTimeSeriesChart data format is already correct and matching between backend and frontend. Backend sends PowerSample via WebSocket with all required fields: timestamp (relative_time_ms), cpu_power_mw, gpu_power_mw, ane_power_mw, dram_power_mw, total_power_mw, phase. Frontend PowerSample TypeScript interface expects exactly these fields. ProfilingContext correctly extracts message.data and adds to powerSamples array. All types validate correctly with TypeScript compilation succeeding. The data flow from backend -> WebSocket -> frontend is fully aligned. This bug was likely fixed as a side effect of BUG-013 (timestamp fix).
Files Modified: None (already fixed)

[2026-01-14] BUG-011 - COMPLETED
Status: Fixed WebSocket reconnection race condition
Description: Fixed race condition in profilingWebsocket.ts reconnection logic that could cause duplicate connections during rapid connect/disconnect cycles. Added 'disconnecting' state to ConnectionState type to track when disconnect is in progress. Enhanced connect() method to: (1) check connectionState instead of just ws.readyState to prevent new connections during disconnecting, (2) cancel any pending reconnection timer before connecting to prevent duplicate scheduled reconnections. Enhanced scheduleReconnect() to: (1) prevent reconnection if already connecting/connected, (2) prevent scheduling multiple reconnection attempts by returning early if reconnectTimer already exists, (3) clear reconnectTimer reference after timeout fires. Enhanced disconnect() to: (1) set 'disconnecting' state before closing WebSocket to prevent new connections, (2) return early if already disconnected to avoid redundant work. These changes ensure exactly one active WebSocket connection exists during rapid connect/disconnect cycles and prevent orphaned reconnection timers.
Files Modified: src/lib/profilingWebsocket.ts

[2026-01-14] BUG-020 - COMPLETED
Status: Fixed LiveLayerHeatmap not receiving data
Description: Fixed LiveLayerHeatmap showing "Waiting for token generation..." by adding full layer-by-layer metrics to token_complete WebSocket events. The issue was that backend only sent layer_metrics_summary (aggregated stats) but LiveLayerHeatmap expected full LayerMetrics[] array with per-layer component data. Modified backend/profiling/pipeline_profiler.py emit_token_complete_event() to build layer_metrics array by grouping ComponentTiming data by layer_idx, creating proper LayerMetrics structure with layer_index and components array containing component_name, duration_ms, activation_mean/std/max, and sparsity for each component. Updated backend/main.py stream_token_complete callback to include layer_metrics field in WebSocket message. Updated frontend src/types/index.ts TokenCompleteMessage interface to include optional layer_metrics field. Updated src/components/profiling/ProfilingContext.tsx to map message.layer_metrics to token.layers instead of hardcoded empty array. Now LiveLayerHeatmap receives full layer data and displays real-time heatmap visualization showing component activity (q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj, layer norms) across all layers for each generated token.
Files Modified: backend/profiling/pipeline_profiler.py, backend/main.py, src/types/index.ts, src/components/profiling/ProfilingContext.tsx

[2026-01-14] BUG-015 - COMPLETED
Status: Fixed ProfilingContext token mapping
Description: Fixed field name mismatches between backend and frontend for token_complete WebSocket events. Backend was sending 'token_index' but frontend expected 'token_position', and backend was sending 'avg_power_mw' but frontend expected 'power_snapshot_mw'. Updated backend/profiling/pipeline_profiler.py emit_token_complete_event() to send token_position instead of token_index and power_snapshot_mw instead of avg_power_mw in the token_data dictionary. This ensures all TokenMetrics fields are properly populated in the frontend, fixing undefined values in hover tooltips, React DevTools, and any component using token metrics. Now all token data fields (token_position, token_text, duration_ms, energy_mj, power_snapshot_mw, layer_metrics) map correctly between backend and frontend.
Files Modified: backend/profiling/pipeline_profiler.py

