# Energy Profiler Progress Log
Created: 2026-01-13

## Project Overview
Energy and power profiling system for transformer inference on Apple Silicon M4 Max.
Features: powermetrics integration, per-layer/per-token profiling, SQLite storage, comprehensive visualizations.

---

## 2026-01-13
### EP-001: Project Setup and Dependencies - COMPLETED
- Added pynvml and psutil to backend/requirements.txt for power monitoring
- Added d3 and d3-sankey to package.json for frontend visualizations
- Added TypeScript type definitions for d3 libraries
- Created backend/profiling/ directory structure
- Created src/components/profiling/charts/ directory structure
- Created backend/profiling/__init__.py with module documentation
- Verified Python syntax and TypeScript compilation (npm build successful)

### EP-002: Sudoers Configuration for powermetrics - COMPLETED
- Created setup_powermetrics.sh script for automated sudoers configuration
- Added comprehensive README_POWERMETRICS.md documentation
- Implemented profiling/utils.py with powermetrics verification functions
- Added verification check to backend startup (main.py lifespan)
- Added graceful fallback messages when powermetrics unavailable
- Added /api/profiling/powermetrics/status endpoint
- Verified Python syntax with py_compile

### EP-003: PowerMonitor Class - Basic Implementation - COMPLETED
- Created backend/profiling/power_monitor.py
- Implemented PowerMonitor.__init__ with configurable sample_interval_ms parameter
- Implemented PowerMonitor.start() to spawn powermetrics subprocess with plist output
- Implemented PowerMonitor.stop() to terminate subprocess and finalize collection
- Implemented PowerMonitor.is_available() class method for permission checking
- Added PowerSample dataclass for structured power measurements
- Added context manager support (__enter__, __exit__)
- Added is_running(), get_samples(), and get_current() methods
- Verified Python syntax with py_compile (no errors)

### EP-004: PowerMonitor Class - Plist Parsing - COMPLETED
- Imported plistlib for parsing XML plist output from powermetrics
- Implemented _parse_plist_sample() method to extract power metrics from plist dictionary
- Extracts CPU power by summing all cluster power values
- Extracts GPU power from processor.gpu.gpu_power field
- Extracts ANE (Apple Neural Engine) power from processor.ane.power field
- Extracts DRAM power by summing thermal channels with 'DRAM' in name
- Calculates total_power_mw as sum of all components
- Implemented _sampling_loop() background thread for continuous plist parsing
- Buffers incoming plist XML until complete (detecting </plist> end tag)
- Handles parsing errors gracefully with warning messages (no crashes)
- Updated start() to launch background sampling thread
- Updated stop() to properly join sampling thread with timeout
- PowerSample dataclass already existed with all required fields
- Verified Python syntax with py_compile (no errors)

### EP-005: PowerMonitor Class - Async Sampling Thread - COMPLETED
- Added threading.Lock (_samples_lock) for thread-safe sample collection
- Background sampling thread already implemented in _sampling_loop() (from EP-004)
- Protected _samples.append() with lock in _sampling_loop()
- Protected get_samples() with lock to return thread-safe copy
- Protected get_current() with lock for latest sample access
- get_current() returns Optional[PowerSample] (latest sample or None)
- get_samples() returns List[PowerSample] (copy of all samples)
- Thread cleanup already implemented in stop() with join(timeout=2)
- Daemon thread ensures no hanging threads on process exit
- Verified Python syntax with py_compile (no errors)

### EP-006: SQLite Database Schema Creation - COMPLETED
- Created backend/profiling/database.py with full schema implementation
- Defined profiling_runs table with metadata (run_id, timestamp, model, prompt, response, tags, etc.)
- Defined power_samples table for raw power measurements (CPU, GPU, ANE, DRAM, total)
- Defined pipeline_sections table for phase/section timing and energy
- Defined tokens table for per-token metrics during decode phase
- Defined layer_metrics table for per-layer per-token profiling data
- Defined component_metrics table for attention/MLP/layernorm component metrics
- Defined deep_operation_metrics table for lowest-level operation profiling (optional)
- Created comprehensive indexes for query performance (run_id, timestamp, model, tags, etc.)
- Implemented ProfileDatabase class with connect(), close(), and _create_schema() methods
- Implemented init_database() helper function for easy initialization
- Added CASCADE DELETE constraints for data integrity
- Enabled sqlite3.Row factory for column access by name
- Verified Python syntax with py_compile (no errors)

### EP-007: ProfileDatabase Class - CRUD Operations - COMPLETED
- Implemented create_run() method to insert new profiling run with all metadata fields
- Implemented add_power_samples() with batch insert using executemany() for performance
- Implemented add_pipeline_section() to insert section timing and energy data
- Implemented add_token() to insert per-token metrics during inference
- Implemented add_layer_metrics() with batch insert for per-layer per-token data
- Implemented add_component_metrics() with batch insert for attention/MLP/layernorm components
- Implemented add_deep_operation_metrics() with batch insert for lowest-level operations
- All methods include comprehensive docstrings with argument descriptions
- All methods return appropriate values (row IDs for create operations, None for batch inserts)
- All methods use parameterized queries to prevent SQL injection
- All batch insert methods use executemany() for performance
- Proper handling of Optional fields with .get() method on dictionaries
- Added debug logging for all insert operations
- Verified Python syntax with py_compile (no errors)

### EP-008: ProfileDatabase Class - Query Methods - COMPLETED
- Implemented get_run(run_id) to retrieve full run data by run identifier
- Implemented get_runs() with comprehensive filtering (model, date_from, date_to, tags, experiment)
- Added pagination support to get_runs() with limit and offset parameters
- Added sorting by timestamp DESC for chronological ordering
- Implemented get_run_summary(run_id) for aggregated statistics
  - Includes phase breakdown with total duration, energy, power per phase
  - Includes average metrics per layer across all tokens
  - Includes average metrics per component (q_proj, k_proj, etc.) across all occurrences
  - Identifies hottest components (top 10 by energy consumption)
- Implemented get_tokens(run_id) to retrieve all tokens with metrics ordered by index
- Implemented get_layer_metrics(token_id) to retrieve layer metrics for a specific token
- Implemented get_component_metrics(layer_metric_id) to retrieve component metrics for a layer
- Implemented get_power_timeline(run_id) to retrieve all power samples ordered by timestamp
- Implemented search_by_prompt(query_string) for full-text search in prompt field
- Implemented delete_run(run_id) with CASCADE DELETE for all related records
- All query methods return List[dict] or Optional[dict] for easy JSON serialization
- All methods use parameterized queries to prevent SQL injection
- Complex aggregation queries with JOINs and GROUP BY for summary statistics
- Verified Python syntax with py_compile (no errors)

### EP-009: Model Architecture Detector - COMPLETED
- Created backend/profiling/model_detector.py with architecture detection capabilities
- Implemented ComponentPaths dataclass for standardized component path storage
- Implemented ModelArchitectureDetector class with detect() method
- Added detection for Llama architecture (meta-llama models)
  - Returns paths for q_proj, k_proj, v_proj, o_proj attention components
  - Returns paths for gate_proj, up_proj, down_proj MLP components
  - Returns paths for input_layernorm and post_attention_layernorm
  - Detects RMSNorm usage in Llama models
- Added detection for Mistral architecture (uses same structure as Llama)
- Added detection for Phi architecture (microsoft/phi models)
  - Supports both Phi-3 style (with gate_proj) and older Phi style (fc1/fc2)
  - Detects LayerNorm usage in Phi models
- Added detection for Qwen architecture (Qwen/Qwen2 models)
  - Uses similar structure to Llama with RMSNorm
- Implemented fallback detection for unknown architectures
  - Attempts to infer structure by inspecting model attributes
  - Searches for layers in model.layers, model.model.layers, or transformer.h
  - Detects attention component naming (self_attn vs attn)
  - Detects MLP component naming (gate_proj/up_proj/down_proj vs fc1/fc2)
  - Detects norm type (RMSNorm vs LayerNorm) by class name inspection
  - Logs warnings when using fallback detection
- Added structure detection helper methods (_is_llama_structure, _is_mistral_structure, etc.)
- Added comprehensive logging throughout detection process
- Added convenience function detect_model_architecture(model)
- Verified Python syntax with py_compile (no errors)

### EP-010: LayerProfiler Class - Hook Registration - COMPLETED
- Created backend/profiling/layer_profiler.py with comprehensive hook registration
- Implemented ComponentTiming dataclass to store timing and activation statistics per component
- Implemented LayerProfiler.__init__ with model reference and configuration options
  - capture_activations parameter to enable/disable activation statistics
  - sparsity_threshold parameter for configurable sparsity calculation
- Integrated ModelArchitectureDetector to automatically detect component paths
- Implemented register_hooks() method to register forward hooks on all model components
  - Pre-hooks capture start time using time.perf_counter()
  - Post-hooks capture end time and compute duration in milliseconds
- Registered hooks on attention components (q_proj, k_proj, v_proj, o_proj)
- Registered hooks on MLP components (gate_proj, up_proj, down_proj)
  - Handles architectures without gate_proj (older Phi models)
- Registered hooks on layer normalizations (input_layernorm, post_attention_layernorm)
- Stores all hook handles for later removal in self.hook_handles list
- Implemented activation statistics capture in post-hooks
  - activation_mean: mean of absolute values
  - activation_std: standard deviation
  - activation_max: maximum absolute value
  - activation_sparsity: fraction of near-zero values based on threshold
  - Uses torch.mps.synchronize() on Apple Silicon for accurate timing
  - Handles tuple outputs from modules that return multiple values
- Implemented get_timings() to retrieve all captured timing data
- Implemented reset() to clear timings between tokens or inference runs
- Implemented detach() to remove all hooks from model
- Added context manager support (__enter__, __exit__) for automatic cleanup
- Added _get_layers() helper to access layers using detected path
- Added _register_layer_hooks() to register hooks on all components within a layer
- Added _register_component_hook() to register pre-hook and post-hook on specific component
- Comprehensive error handling and logging throughout
- Verified Python syntax with py_compile (no errors)

### EP-011: LayerProfiler Class - Timing Capture - COMPLETED
- Enhanced LayerProfiler with thread-local storage for concurrent safety
- Added threading.local() for thread-local timing storage (_local attribute)
- Added threading.Lock() for thread-safe access to timings (_timings_lock)
- Implemented _get_thread_timings() helper method to get or create thread-local timings list
- Updated post-hook to store timings in thread-local storage using _get_thread_timings()
- Pre-hook already implemented to record start time using time.perf_counter() (from EP-010)
- Post-hook already implemented to record end time and calculate duration_ms (from EP-010)
- torch.mps.synchronize() already implemented in post-hook for Apple Silicon timing (from EP-010)
- Updated get_timings() to use lock and retrieve timings from thread-local storage
  - Returns copy of thread-local timings list for safety
  - Protected by _timings_lock for thread-safe access
- Updated reset() to clear thread-local timings with lock protection
  - Clears timings for current thread only
  - Protected by _timings_lock for thread-safe access
- All timing capture features now fully thread-safe and concurrent-ready
- Verified Python syntax with py_compile (no errors)

### EP-012: LayerProfiler Class - Activation Statistics - COMPLETED
- Verified all activation statistics already implemented in LayerProfiler post-hook
- Activation statistics captured from hook outputs (lines 218-241 in layer_profiler.py):
  - activation_mean: computed using output.abs().mean().item() (line 235)
  - activation_std: computed using output.std().item() (line 236)
  - activation_max: computed using output.abs().max().item() (line 237)
  - activation_sparsity: computed as fraction of near-zero values (lines 240-241)
    - Uses (output.abs() < threshold).float().mean().item()
- Sparsity threshold is configurable via __init__ parameter (default: 1e-4)
- Statistics stored per component per forward pass in ComponentTiming dataclass
- Handles tuple outputs from modules that return multiple values (lines 223-226)
- Uses torch.mps.synchronize() on Apple Silicon for accurate measurements (lines 231-232)
- Error handling with logging for any statistics capture failures (lines 243-244)
- Feature already implemented in EP-010 and EP-011, now formally verified
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-012 passes = true

### EP-013: LayerProfiler Class - Cleanup - COMPLETED
- Enhanced detach() method to ensure complete cleanup (lines 278-302)
  - Removes all hooks from model with try/except error handling per hook
  - Clears hook_handles list after removal
  - Resets _hooks_registered flag to False
  - Clears all stored timing metrics from thread-local storage
  - Uses _timings_lock for thread-safe metric clearing
  - Added comprehensive logging for cleanup confirmation
- Context manager already implemented (__enter__, __exit__ methods at lines 304-311)
  - __enter__ calls register_hooks() to set up profiling
  - __exit__ calls detach() to ensure cleanup
  - Returns False to not suppress exceptions (proper exception propagation)
- Exception safety ensured throughout:
  - detach() has try/except around individual hook removal to prevent partial cleanup failures
  - __exit__ always calls detach() even if exceptions occur during profiling
  - Exceptions are properly propagated to caller (not suppressed)
- All stored metrics cleared on cleanup:
  - Thread-local timings list cleared with thread-safe lock
  - Hook handles list cleared
  - All cleanup is idempotent (safe to call multiple times)
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-013 passes = true

