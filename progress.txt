# Energy Profiler Progress Log
Created: 2026-01-13

## Project Overview
Energy and power profiling system for transformer inference on Apple Silicon M4 Max.
Features: powermetrics integration, per-layer/per-token profiling, SQLite storage, comprehensive visualizations.

---

## 2026-01-13
### EP-001: Project Setup and Dependencies - COMPLETED
- Added pynvml and psutil to backend/requirements.txt for power monitoring
- Added d3 and d3-sankey to package.json for frontend visualizations
- Added TypeScript type definitions for d3 libraries
- Created backend/profiling/ directory structure
- Created src/components/profiling/charts/ directory structure
- Created backend/profiling/__init__.py with module documentation
- Verified Python syntax and TypeScript compilation (npm build successful)

### EP-002: Sudoers Configuration for powermetrics - COMPLETED
- Created setup_powermetrics.sh script for automated sudoers configuration
- Added comprehensive README_POWERMETRICS.md documentation
- Implemented profiling/utils.py with powermetrics verification functions
- Added verification check to backend startup (main.py lifespan)
- Added graceful fallback messages when powermetrics unavailable
- Added /api/profiling/powermetrics/status endpoint
- Verified Python syntax with py_compile

### EP-003: PowerMonitor Class - Basic Implementation - COMPLETED
- Created backend/profiling/power_monitor.py
- Implemented PowerMonitor.__init__ with configurable sample_interval_ms parameter
- Implemented PowerMonitor.start() to spawn powermetrics subprocess with plist output
- Implemented PowerMonitor.stop() to terminate subprocess and finalize collection
- Implemented PowerMonitor.is_available() class method for permission checking
- Added PowerSample dataclass for structured power measurements
- Added context manager support (__enter__, __exit__)
- Added is_running(), get_samples(), and get_current() methods
- Verified Python syntax with py_compile (no errors)

### EP-004: PowerMonitor Class - Plist Parsing - COMPLETED
- Imported plistlib for parsing XML plist output from powermetrics
- Implemented _parse_plist_sample() method to extract power metrics from plist dictionary
- Extracts CPU power by summing all cluster power values
- Extracts GPU power from processor.gpu.gpu_power field
- Extracts ANE (Apple Neural Engine) power from processor.ane.power field
- Extracts DRAM power by summing thermal channels with 'DRAM' in name
- Calculates total_power_mw as sum of all components
- Implemented _sampling_loop() background thread for continuous plist parsing
- Buffers incoming plist XML until complete (detecting </plist> end tag)
- Handles parsing errors gracefully with warning messages (no crashes)
- Updated start() to launch background sampling thread
- Updated stop() to properly join sampling thread with timeout
- PowerSample dataclass already existed with all required fields
- Verified Python syntax with py_compile (no errors)

### EP-005: PowerMonitor Class - Async Sampling Thread - COMPLETED
- Added threading.Lock (_samples_lock) for thread-safe sample collection
- Background sampling thread already implemented in _sampling_loop() (from EP-004)
- Protected _samples.append() with lock in _sampling_loop()
- Protected get_samples() with lock to return thread-safe copy
- Protected get_current() with lock for latest sample access
- get_current() returns Optional[PowerSample] (latest sample or None)
- get_samples() returns List[PowerSample] (copy of all samples)
- Thread cleanup already implemented in stop() with join(timeout=2)
- Daemon thread ensures no hanging threads on process exit
- Verified Python syntax with py_compile (no errors)

### EP-006: SQLite Database Schema Creation - COMPLETED
- Created backend/profiling/database.py with full schema implementation
- Defined profiling_runs table with metadata (run_id, timestamp, model, prompt, response, tags, etc.)
- Defined power_samples table for raw power measurements (CPU, GPU, ANE, DRAM, total)
- Defined pipeline_sections table for phase/section timing and energy
- Defined tokens table for per-token metrics during decode phase
- Defined layer_metrics table for per-layer per-token profiling data
- Defined component_metrics table for attention/MLP/layernorm component metrics
- Defined deep_operation_metrics table for lowest-level operation profiling (optional)
- Created comprehensive indexes for query performance (run_id, timestamp, model, tags, etc.)
- Implemented ProfileDatabase class with connect(), close(), and _create_schema() methods
- Implemented init_database() helper function for easy initialization
- Added CASCADE DELETE constraints for data integrity
- Enabled sqlite3.Row factory for column access by name
- Verified Python syntax with py_compile (no errors)

### EP-007: ProfileDatabase Class - CRUD Operations - COMPLETED
- Implemented create_run() method to insert new profiling run with all metadata fields
- Implemented add_power_samples() with batch insert using executemany() for performance
- Implemented add_pipeline_section() to insert section timing and energy data
- Implemented add_token() to insert per-token metrics during inference
- Implemented add_layer_metrics() with batch insert for per-layer per-token data
- Implemented add_component_metrics() with batch insert for attention/MLP/layernorm components
- Implemented add_deep_operation_metrics() with batch insert for lowest-level operations
- All methods include comprehensive docstrings with argument descriptions
- All methods return appropriate values (row IDs for create operations, None for batch inserts)
- All methods use parameterized queries to prevent SQL injection
- All batch insert methods use executemany() for performance
- Proper handling of Optional fields with .get() method on dictionaries
- Added debug logging for all insert operations
- Verified Python syntax with py_compile (no errors)

### EP-008: ProfileDatabase Class - Query Methods - COMPLETED
- Implemented get_run(run_id) to retrieve full run data by run identifier
- Implemented get_runs() with comprehensive filtering (model, date_from, date_to, tags, experiment)
- Added pagination support to get_runs() with limit and offset parameters
- Added sorting by timestamp DESC for chronological ordering
- Implemented get_run_summary(run_id) for aggregated statistics
  - Includes phase breakdown with total duration, energy, power per phase
  - Includes average metrics per layer across all tokens
  - Includes average metrics per component (q_proj, k_proj, etc.) across all occurrences
  - Identifies hottest components (top 10 by energy consumption)
- Implemented get_tokens(run_id) to retrieve all tokens with metrics ordered by index
- Implemented get_layer_metrics(token_id) to retrieve layer metrics for a specific token
- Implemented get_component_metrics(layer_metric_id) to retrieve component metrics for a layer
- Implemented get_power_timeline(run_id) to retrieve all power samples ordered by timestamp
- Implemented search_by_prompt(query_string) for full-text search in prompt field
- Implemented delete_run(run_id) with CASCADE DELETE for all related records
- All query methods return List[dict] or Optional[dict] for easy JSON serialization
- All methods use parameterized queries to prevent SQL injection
- Complex aggregation queries with JOINs and GROUP BY for summary statistics
- Verified Python syntax with py_compile (no errors)

### EP-009: Model Architecture Detector - COMPLETED
- Created backend/profiling/model_detector.py with architecture detection capabilities
- Implemented ComponentPaths dataclass for standardized component path storage
- Implemented ModelArchitectureDetector class with detect() method
- Added detection for Llama architecture (meta-llama models)
  - Returns paths for q_proj, k_proj, v_proj, o_proj attention components
  - Returns paths for gate_proj, up_proj, down_proj MLP components
  - Returns paths for input_layernorm and post_attention_layernorm
  - Detects RMSNorm usage in Llama models
- Added detection for Mistral architecture (uses same structure as Llama)
- Added detection for Phi architecture (microsoft/phi models)
  - Supports both Phi-3 style (with gate_proj) and older Phi style (fc1/fc2)
  - Detects LayerNorm usage in Phi models
- Added detection for Qwen architecture (Qwen/Qwen2 models)
  - Uses similar structure to Llama with RMSNorm
- Implemented fallback detection for unknown architectures
  - Attempts to infer structure by inspecting model attributes
  - Searches for layers in model.layers, model.model.layers, or transformer.h
  - Detects attention component naming (self_attn vs attn)
  - Detects MLP component naming (gate_proj/up_proj/down_proj vs fc1/fc2)
  - Detects norm type (RMSNorm vs LayerNorm) by class name inspection
  - Logs warnings when using fallback detection
- Added structure detection helper methods (_is_llama_structure, _is_mistral_structure, etc.)
- Added comprehensive logging throughout detection process
- Added convenience function detect_model_architecture(model)
- Verified Python syntax with py_compile (no errors)

### EP-010: LayerProfiler Class - Hook Registration - COMPLETED
- Created backend/profiling/layer_profiler.py with comprehensive hook registration
- Implemented ComponentTiming dataclass to store timing and activation statistics per component
- Implemented LayerProfiler.__init__ with model reference and configuration options
  - capture_activations parameter to enable/disable activation statistics
  - sparsity_threshold parameter for configurable sparsity calculation
- Integrated ModelArchitectureDetector to automatically detect component paths
- Implemented register_hooks() method to register forward hooks on all model components
  - Pre-hooks capture start time using time.perf_counter()
  - Post-hooks capture end time and compute duration in milliseconds
- Registered hooks on attention components (q_proj, k_proj, v_proj, o_proj)
- Registered hooks on MLP components (gate_proj, up_proj, down_proj)
  - Handles architectures without gate_proj (older Phi models)
- Registered hooks on layer normalizations (input_layernorm, post_attention_layernorm)
- Stores all hook handles for later removal in self.hook_handles list
- Implemented activation statistics capture in post-hooks
  - activation_mean: mean of absolute values
  - activation_std: standard deviation
  - activation_max: maximum absolute value
  - activation_sparsity: fraction of near-zero values based on threshold
  - Uses torch.mps.synchronize() on Apple Silicon for accurate timing
  - Handles tuple outputs from modules that return multiple values
- Implemented get_timings() to retrieve all captured timing data
- Implemented reset() to clear timings between tokens or inference runs
- Implemented detach() to remove all hooks from model
- Added context manager support (__enter__, __exit__) for automatic cleanup
- Added _get_layers() helper to access layers using detected path
- Added _register_layer_hooks() to register hooks on all components within a layer
- Added _register_component_hook() to register pre-hook and post-hook on specific component
- Comprehensive error handling and logging throughout
- Verified Python syntax with py_compile (no errors)

### EP-011: LayerProfiler Class - Timing Capture - COMPLETED
- Enhanced LayerProfiler with thread-local storage for concurrent safety
- Added threading.local() for thread-local timing storage (_local attribute)
- Added threading.Lock() for thread-safe access to timings (_timings_lock)
- Implemented _get_thread_timings() helper method to get or create thread-local timings list
- Updated post-hook to store timings in thread-local storage using _get_thread_timings()
- Pre-hook already implemented to record start time using time.perf_counter() (from EP-010)
- Post-hook already implemented to record end time and calculate duration_ms (from EP-010)
- torch.mps.synchronize() already implemented in post-hook for Apple Silicon timing (from EP-010)
- Updated get_timings() to use lock and retrieve timings from thread-local storage
  - Returns copy of thread-local timings list for safety
  - Protected by _timings_lock for thread-safe access
- Updated reset() to clear thread-local timings with lock protection
  - Clears timings for current thread only
  - Protected by _timings_lock for thread-safe access
- All timing capture features now fully thread-safe and concurrent-ready
- Verified Python syntax with py_compile (no errors)

### EP-012: LayerProfiler Class - Activation Statistics - COMPLETED
- Verified all activation statistics already implemented in LayerProfiler post-hook
- Activation statistics captured from hook outputs (lines 218-241 in layer_profiler.py):
  - activation_mean: computed using output.abs().mean().item() (line 235)
  - activation_std: computed using output.std().item() (line 236)
  - activation_max: computed using output.abs().max().item() (line 237)
  - activation_sparsity: computed as fraction of near-zero values (lines 240-241)
    - Uses (output.abs() < threshold).float().mean().item()
- Sparsity threshold is configurable via __init__ parameter (default: 1e-4)
- Statistics stored per component per forward pass in ComponentTiming dataclass
- Handles tuple outputs from modules that return multiple values (lines 223-226)
- Uses torch.mps.synchronize() on Apple Silicon for accurate measurements (lines 231-232)
- Error handling with logging for any statistics capture failures (lines 243-244)
- Feature already implemented in EP-010 and EP-011, now formally verified
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-012 passes = true

### EP-013: LayerProfiler Class - Cleanup - COMPLETED
- Enhanced detach() method to ensure complete cleanup (lines 278-302)
  - Removes all hooks from model with try/except error handling per hook
  - Clears hook_handles list after removal
  - Resets _hooks_registered flag to False
  - Clears all stored timing metrics from thread-local storage
  - Uses _timings_lock for thread-safe metric clearing
  - Added comprehensive logging for cleanup confirmation
- Context manager already implemented (__enter__, __exit__ methods at lines 304-311)
  - __enter__ calls register_hooks() to set up profiling
  - __exit__ calls detach() to ensure cleanup
  - Returns False to not suppress exceptions (proper exception propagation)
- Exception safety ensured throughout:
  - detach() has try/except around individual hook removal to prevent partial cleanup failures
  - __exit__ always calls detach() even if exceptions occur during profiling
  - Exceptions are properly propagated to caller (not suppressed)
- All stored metrics cleared on cleanup:
  - Thread-local timings list cleared with thread-safe lock
  - Hook handles list cleared
  - All cleanup is idempotent (safe to call multiple times)
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-013 passes = true

### EP-014: DeepAttentionProfiler - Monkey Patch Approach - COMPLETED
- Created backend/profiling/deep_profiler.py with deep operation profiling capabilities
- Implemented AttentionOperationMetrics dataclass for individual attention operation timings
  - qk_matmul_time: Time for Q @ K^T matrix multiplication
  - scale_time: Time for attention score scaling
  - mask_time: Time for mask application
  - softmax_time: Time for softmax operation
  - value_matmul_time: Time for attention @ V matrix multiplication
  - total_time: Total attention module time
- Implemented DeepOperationMetrics dataclass for complete profiling session metrics
- Implemented DeepAttentionProfiler class with model reference in __init__
- Stored original attention forward methods in dictionary (self.original_forwards)
- Implemented _find_attention_modules() to locate all attention modules in model
  - Searches for common attention patterns: 'self_attn', 'attention', 'attn', 'self_attention'
  - Returns list of (name, module) tuples for patching
- Created _create_instrumented_forward() wrapper function for timing capture
  - Wraps original forward method with pre/post timing
  - Uses time.perf_counter() for high-resolution timing
  - Uses torch.mps.synchronize() on Apple Silicon for accurate measurements
  - Stores metrics in thread-local storage for thread safety
  - Falls back to original behavior on any profiling errors
- Created _create_detailed_instrumented_forward() for detailed attention profiling
  - Accepts standard attention forward signature (hidden_states, attention_mask, etc.)
  - Captures total attention time (individual operations require deeper introspection)
  - Handles HuggingFace attention interface with past_key_value, use_cache, etc.
- Implemented patch() method to apply monkey-patching to all attention modules
  - Stores original forward methods before patching
  - Replaces module.forward with instrumented version
  - Tries detailed instrumentation first, falls back to simple version
  - Sets is_patched flag to prevent double-patching
- Implemented unpatch() method to restore original forward methods
  - Restores all original forwards from stored dictionary
  - Clears original_forwards dictionary after restoration
  - Sets is_patched flag to False
- Implemented get_metrics() to retrieve all collected AttentionOperationMetrics
- Implemented reset() to clear thread-local metrics storage
- Added context manager support (__enter__, __exit__) for automatic patch/unpatch lifecycle
- Thread-local storage (threading.local()) ensures thread-safe metric collection
- Comprehensive error handling prevents profiling failures from affecting inference
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-014 passes = true

### EP-015: DeepAttentionProfiler - Extra Metrics - COMPLETED
- Extended AttentionOperationMetrics dataclass with additional attention metrics
  - attention_entropy_per_head: List[float] - Shannon entropy for each attention head
  - max_attention_weight_per_head: List[float] - Maximum attention weight per head
  - attention_sparsity_per_head: List[float] - Fraction of near-zero weights per head
  - avg_attention_entropy: float - Average entropy across all heads
  - avg_max_attention_weight: float - Average max weight across all heads
  - avg_attention_sparsity: float - Average sparsity across all heads
- Implemented _compute_attention_metrics() static method for detailed attention analysis
  - Accepts attention_weights tensor of shape (batch, num_heads, seq_len, seq_len)
  - Computes Shannon entropy per head: -sum(p * log(p)) averaged across query positions
  - Computes maximum attention weight per head for focus analysis
  - Computes sparsity per head with configurable threshold (default: 0.01)
  - Handles both 4D (multi-head) and 3D (single-head) attention weight tensors
  - Averages metrics across batch dimension for stability
  - Returns dictionary with per-head metrics and cross-head averages
  - Includes epsilon (1e-10) to prevent log(0) in entropy calculation
- Enhanced _create_detailed_instrumented_forward() to capture attention weights
  - Forces output_attentions=True internally to access attention weights
  - Extracts attention weights from forward return tuple (typically second element)
  - Calls _compute_attention_metrics() to compute all extra metrics
  - Stores computed metrics in AttentionOperationMetrics dataclass
  - Respects original output_attentions parameter in return value (strips weights if not requested)
  - Graceful fallback if attention weights unavailable or metric computation fails
- Enhanced _create_instrumented_forward() (simple version) with same attention metric capture
  - Attempts to request attention weights via output_attentions=True
  - Computes and stores extra metrics when weights available
  - Returns result in original format matching user's output_attentions parameter
  - Error handling prevents profiling failures from affecting inference
- Tested implementation with synthetic attention weights (shape: 1, 4, 10, 10)
  - Verified entropy computation returns reasonable values (~1.9 for uniform attention)
  - Verified max weight computation detects peak attention values (~0.5)
  - Verified sparsity computation with configurable threshold (~0.03 for softmax output)
  - Confirmed per-head metrics stored as lists with correct length (num_heads)
  - Confirmed averages computed correctly across heads
- Verified Python syntax with py_compile (no errors)
- Verified module imports successfully with all new fields present
- Updated PRD: EP-015 passes = true

### EP-016: DeepAttentionProfiler - MLP Operations - COMPLETED
- Extended DeepAttentionProfiler to profile MLP (Multi-Layer Perceptron) operations
- Created MLPOperationMetrics dataclass for individual MLP operation timings
  - gate_proj_time: Time for gate projection and activation (GELU/SiLU)
  - up_proj_time: Time for up projection and activation
  - gate_up_mult_time: Time for gate * up element-wise multiplication
  - down_proj_time: Time for down projection
  - total_time: Total MLP module time
  - activation_kill_ratio: Percentage of negative inputs to activation function
- Updated DeepOperationMetrics dataclass to include mlp_ops field
- Added original_mlp_forwards dictionary to store original MLP forward methods
- Implemented _find_mlp_modules() to locate all MLP modules in model
  - Searches for common MLP patterns: 'mlp', 'feed_forward', 'ffn', 'fc'
  - Excludes attention modules from MLP detection
  - Returns list of (name, module) tuples for patching
- Implemented _create_instrumented_mlp_forward() wrapper function
  - Instruments gated MLP architectures (Llama, Mistral style)
  - Times gate projection and applies activation function (GELU/SiLU)
  - Times up projection separately
  - Times gate * up element-wise multiplication
  - Times down projection
  - Computes activation kill ratio from gate projection inputs (negative input percentage)
  - Uses torch.mps.synchronize() on Apple Silicon for accurate timing
  - Stores metrics in thread-local storage (self.metrics_storage.mlp_metrics)
  - Falls back to original behavior on any profiling errors
- Enhanced patch() method to patch both attention and MLP modules
  - Patches attention modules (existing behavior)
  - Patches MLP modules with instrumented MLP forward
  - Sets is_patched flag after both types are patched
- Enhanced unpatch() method to restore both attention and MLP modules
  - Restores original attention forwards (existing behavior)
  - Restores original MLP forwards from stored dictionary
  - Clears both original_forwards and original_mlp_forwards dictionaries
- Implemented get_mlp_metrics() to retrieve all collected MLPOperationMetrics
- Enhanced reset() to clear both attention and MLP metrics from thread-local storage
- All MLP profiling is thread-safe using threading.local() storage
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-016 passes = true

### Paper Analysis: TokenPowerBench (Niu et al. 2025) - COMPLETED
- Reviewed paper: "TokenPowerBench: Benchmarking the Power Consumption of LLM Inference"
- Paper source: arxiv.org/abs/2512.03024 (papers/2512.03024v1.pdf)
- Key findings relevant to our profiler:

**Core Methodology from Paper:**
- Three-layer architecture: Configuration, Execution & Measurement, Report Generation
- Phase-aligned power samples (every sample tagged with prefill/decode/idle)
- Energy formula: E_total = E_Prefill + E_Decode = E_GPU + E_CPU + E_DRAM + E_Others
- Primary metric: Joules per token (J/t)

**Key Experimental Findings:**
1. Energy scales super-linearly with model params: 1B→70B = 7.3× energy (not 70×)
2. MoE models 2-3× more efficient than equivalent dense models
3. Batch size impact: 2-3× energy spread between batch 32-1024, steepest gain at 32-256
4. Context length: 2K→10K tokens = ~3× energy increase
5. Quantization: FP8 cuts energy ~30% vs FP16 with 13-17% throughput boost
6. Parallelism: Pure tensor parallelism (TP=16) beats pipeline parallelism for energy

**Comparison with Our Profiler:**
| Aspect           | TokenPowerBench      | Our Energy Profiler          |
|------------------|----------------------|------------------------------|
| Hardware         | NVIDIA GPUs (H100)   | Apple Silicon M4 Max         |
| Power Source     | NVML/DCGM, RAPL      | powermetrics                 |
| Components       | GPU, CPU, DRAM       | CPU, GPU, ANE, DRAM          |
| Granularity      | Phase-level          | Per-token, per-layer, per-op |
| Inference Engine | vLLM, TensorRT-LLM   | PyTorch direct               |

**Our Advantages:**
- Deeper granularity (per-token, per-layer, per-component, per-operation)
- Apple Neural Engine (ANE) profiling
- Unified memory architecture insights

**New Tasks Added (EP-084 to EP-096):**
- EP-084: Phase-Tagged Power Samples (HIGH)
- EP-085: Peak Power Tracking (HIGH)
- EP-086: Idle Power Baseline Measurement (HIGH)
- EP-087: Batch Size Energy Analysis (MEDIUM)
- EP-088: Energy-Delay Product Metric (MEDIUM)
- EP-089: Cost and Carbon Estimation (MEDIUM)
- EP-090: Component Energy Breakdown Chart (HIGH)
- EP-091: MoE Energy Analysis (LOW)
- EP-092: Energy Scaling Analysis (MEDIUM)
- EP-093: Joules Per Token Metric Standardization (HIGH)
- EP-094: Power Timeline Phase Annotations (MEDIUM)
- EP-095: Inference Engine Comparison Support (LOW)
- EP-096: Throughput vs Energy Tradeoff Analysis (MEDIUM)

**Total PRD Tasks Updated:**
- Before: 83 tasks (13 completed, 70 remaining)
- After: 96 tasks (16 completed, 80 remaining)


### EP-017: DeepAttentionProfiler - LayerNorm Operations - COMPLETED
- Extended DeepAttentionProfiler to profile LayerNorm and RMSNorm operations
- Created LayerNormOperationMetrics dataclass for individual LayerNorm operation timings
  - mean_time: Time for mean computation (hidden_states.mean())
  - variance_time: Time for variance computation (hidden_states.var())
  - normalization_time: Time for normalization operation ((x - mean) / sqrt(variance + eps))
  - scale_shift_time: Time for scale and shift (gamma * normalized + beta)
  - total_time: Total LayerNorm module time
  - variance_ratio: Input variance / output variance (measure of normalization effectiveness)
- Updated DeepOperationMetrics dataclass to include layernorm_ops field
- Added original_layernorm_forwards dictionary to store original LayerNorm forward methods
- Implemented _find_layernorm_modules() to locate all LayerNorm modules in model
  - Searches for common LayerNorm patterns: 'layernorm', 'layer_norm', 'ln', 'rmsnorm', 'rms_norm'
  - Checks both module name and module type (class name)
  - Returns list of (name, module) tuples for patching
- Implemented _create_instrumented_layernorm_forward() wrapper function
  - Instruments both LayerNorm and RMSNorm architectures
  - Times mean computation separately (mean() operation)
  - Times variance computation separately (var() operation with unbiased=False)
  - Times normalization operation (subtract mean, divide by sqrt of variance + epsilon)
  - Times scale and shift operations (weight * normalized + bias)
  - Extracts epsilon from module attributes (eps or variance_epsilon, default 1e-5)
  - Computes variance ratio: input_variance / output_variance for effectiveness measure
  - Handles modules with/without weight and bias parameters (different LayerNorm implementations)
  - Uses torch.mps.synchronize() on Apple Silicon for accurate timing
  - Stores metrics in thread-local storage (self.metrics_storage.layernorm_metrics)
  - Falls back to original behavior on any profiling errors
- Enhanced patch() method to patch attention, MLP, and LayerNorm modules
  - Patches attention modules (existing behavior)
  - Patches MLP modules (EP-016 behavior)
  - Patches LayerNorm modules with instrumented LayerNorm forward
  - Sets is_patched flag after all three types are patched
- Enhanced unpatch() method to restore attention, MLP, and LayerNorm modules
  - Restores original attention forwards (existing behavior)
  - Restores original MLP forwards (EP-016 behavior)
  - Restores original LayerNorm forwards from stored dictionary
  - Clears original_forwards, original_mlp_forwards, and original_layernorm_forwards dictionaries
- Implemented get_layernorm_metrics() to retrieve all collected LayerNormOperationMetrics
- Enhanced reset() to clear attention, MLP, and LayerNorm metrics from thread-local storage
- All LayerNorm profiling is thread-safe using threading.local() storage
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-017 passes = true

### EP-018: DeepAttentionProfiler - Custom Wrapper Approach - COMPLETED
- Created InstrumentedModelWrapper class as alternative to monkey-patching (lines 810-940)
  - Acts as proxy wrapper around original model without modifying it
  - Supports both 'module' and 'deep' profiling_depth configuration
  - Cleaner API: no modification of original model state
  - Easier cleanup: just unwrap, no state restoration needed
  - Safer: original model remains untouched throughout profiling
- Implemented profiling_depth configuration flag with two modes:
  - 'module': Lightweight timing of overall forward pass only
  - 'deep': Detailed operation-level profiling via DeepAttentionProfiler
- Implemented forward() method to intercept layer calls
  - Module mode: times overall model forward pass with synchronization
  - Deep mode: delegates to underlying DeepAttentionProfiler monkey-patches
  - Uses torch.mps.synchronize() on Apple Silicon for accurate timing
  - Thread-safe metric storage with threading.Lock
- Implemented get_metrics() to retrieve profiling data
  - Returns dictionary appropriate for profiling depth
  - Module mode: returns layer_timings list
  - Deep mode: returns attention_ops, mlp_ops, layernorm_ops from DeepAttentionProfiler
- Implemented reset_metrics() to clear all collected metrics
- Implemented cleanup() to properly remove instrumentation
- Added __del__ destructor to ensure cleanup on garbage collection
- Created create_profiled_model() factory function (lines 943-988)
  - Unified API to create profiled models with either approach
  - Parameters: model, profiling_depth ('module'|'deep'), use_wrapper (True|False)
  - Returns tuple of (profiled_model, profiler_object)
  - Supports both wrapper and monkey-patch approaches via config flag
  - Includes comprehensive usage examples in docstring
- Documented tradeoffs between wrapper vs monkey-patch approaches:
  - Wrapper advantages: cleaner API, easier cleanup, safer, better for multiple sessions
  - Monkey-patch advantages: works with any architecture, lower-level interception, no code changes
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-018 passes = true

### EP-019: InferencePipelineProfiler - Core Structure - COMPLETED
- Created backend/profiling/pipeline_profiler.py with main orchestration profiler
- Implemented InferencePipelineProfiler.__init__ accepting all profiler components
  - PowerMonitor: for system power sampling (optional)
  - LayerProfiler: for layer/component metrics (optional)
  - DeepAttentionProfiler: for operation-level metrics (optional)
  - ProfileDatabase: for storing profiling data (optional)
- Implemented _generate_run_id() to create unique UUID4 identifiers
- Implemented run() context manager for profiling session lifecycle
  - Generates unique run_id at session start
  - Starts power monitoring automatically
  - Registers LayerProfiler hooks based on profiling_depth
  - Patches DeepAttentionProfiler for deep profiling
  - Yields ProfilingSession object for section timing
  - Stops power monitoring and cleans up all hooks in finally block
  - Saves complete profiling data to database automatically
- Created ProfilingSession dataclass to hold run context
  - Stores run_id, start_time, prompt, model_name, profiling_depth
  - Stores experiment_name and tags for organization
  - Collects sections list during profiling
  - Holds references to profiler components for access
- Created SectionTiming dataclass for pipeline section metrics
  - Captures phase (pre_inference, prefill, decode, post_inference)
  - Captures section_name, start_time, end_time, duration_ms
  - Calculates energy_mj and avg_power_mw from power samples
  - Stores power_samples that occurred during the section
- Implemented section() context manager method on ProfilingSession
  - Times individual pipeline sections automatically
  - Correlates section timing with power samples for energy calculation
  - Uses torch.mps.synchronize() on Apple Silicon for accurate timing
  - Calculates energy by integrating power over time (trapezoidal rule)
  - Stores SectionTiming in session.sections list
  - Comprehensive logging for section start/complete events
- Implemented _save_run_to_database() private method
  - Calculates total duration and energy from power samples
  - Creates profiling_runs record with all metadata
  - Batch inserts all power samples with add_power_samples()
  - Inserts all pipeline sections with add_pipeline_section()
  - Handles missing database gracefully with warning
  - Comprehensive error handling and logging throughout
- Complete lifecycle management with automatic cleanup
  - Ensures power monitoring stopped even on exceptions
  - Ensures hooks removed even on exceptions
  - Ensures patches removed even on exceptions
  - finally block guarantees cleanup and database save
- Thread-safe and supports concurrent profiling sessions
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-019 passes = true

### EP-020: InferencePipelineProfiler - Section Timing - COMPLETED
- Verified section() context manager already implemented in pipeline_profiler.py
- Implementation analysis (lines 332-429):
  - section() method attached to ProfilingSession class (line 429)
  - Context manager decorator creates proper context (lines 346-425)
  - Records section start timestamp using time.time() (line 348)
  - Calculates start_relative_ms from session start time (line 349)
  - Uses torch.mps.synchronize() before timing for accuracy (lines 354-359)
  - Records section end timestamp using time.time() (line 373)
  - Calculates end_relative_ms and duration_ms (lines 374-375)
  - Correlates with power samples for energy calculation (lines 377-407)
    - Filters samples within section's time range (lines 386-388)
    - Integrates power over time using trapezoidal rule (lines 391-402)
    - Calculates average power for the section (line 402)
    - Handles single sample case with estimation (lines 403-406)
  - Stores section data in SectionTiming dataclass (lines 409-418)
  - Appends to session.sections list for database storage (line 421)
  - Comprehensive logging for section start and completion (lines 351, 423)
- SectionTiming dataclass properly defined (lines 49-59):
  - phase: Pipeline phase identifier
  - section_name: Section identifier within phase
  - start_time, end_time: Absolute timestamps
  - duration_ms: Computed duration in milliseconds
  - energy_mj: Computed energy consumption in millijoules
  - avg_power_mw: Average power draw in milliwatts
  - power_samples: List of PowerSample objects during section
- Database save integration verified in _save_run_to_database() (lines 315-326)
- All EP-020 requirements met and implemented
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-020 passes = true

### EP-021: InferencePipelineProfiler - Pre-Inference Phase - COMPLETED
- Implemented pre-inference phase profiling helper methods in InferencePipelineProfiler
- Added profile_tokenization() method (lines 331-349):
  - Wraps tokenizer.encode() with section timing
  - Uses session.section("tokenization", "pre_inference") context manager
  - Returns tokenized output for pipeline continuation
  - Comprehensive docstring with usage example
- Added profile_tensor_transfer() method (lines 351-370):
  - Wraps tensor.to(device) with section timing
  - Uses session.section("tensor_transfer", "pre_inference") context manager
  - Supports any device target (mps, cuda, cpu)
  - Returns transferred tensor for pipeline continuation
  - Comprehensive docstring with usage example
- Added profile_kv_cache_init() method (lines 372-393):
  - Wraps KV-cache initialization function with section timing
  - Uses session.section("kv_cache_init", "pre_inference") context manager
  - Accepts arbitrary init function with *args and **kwargs for flexibility
  - Returns result from init_func for pipeline continuation
  - Comprehensive docstring with usage example
- All methods leverage existing section() context manager for automatic energy correlation
- Pre-inference metrics automatically stored in session.sections list
- Database integration already handled by existing _save_run_to_database() method
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-021 passes = true

### EP-022: InferencePipelineProfiler - Prefill Phase - COMPLETED
- Implemented prefill phase profiling helper methods in InferencePipelineProfiler
- Added profile_embedding_lookup() method (lines 396-416):
  - Wraps embedding lookup function with section timing
  - Uses session.section("embedding_lookup", "prefill") context manager
  - Accepts arbitrary embedding function with *args and **kwargs for flexibility
  - Returns embedding tensor for pipeline continuation
  - Comprehensive docstring with usage example showing model.embed_tokens
- Added profile_position_embedding() method (lines 418-438):
  - Wraps position embedding function with section timing
  - Uses session.section("position_embedding", "prefill") context manager
  - Supports various positional encoding implementations
  - Returns result with position embeddings added
  - Comprehensive docstring with usage example
- Added profile_transformer_layers() method (lines 440-463):
  - Wraps transformer layers forward pass with section timing
  - Uses session.section("layers", "prefill") context manager
  - LayerProfiler hooks automatically capture detailed per-layer metrics
  - Returns output from transformer layers
  - Comprehensive docstring explaining hook integration
- Added profile_final_layernorm() method (lines 465-485):
  - Wraps final layer normalization with section timing
  - Uses session.section("final_layernorm", "prefill") context manager
  - Returns normalized output for LM head projection
  - Comprehensive docstring with usage example
- Added profile_lm_head() method (lines 487-509):
  - Wraps language model head projection with section timing
  - Uses session.section("lm_head", "prefill") context manager
  - Projects hidden states to vocabulary logits
  - Returns vocabulary logits for token sampling
  - Comprehensive docstring with usage example
- Added profile_kv_cache_store() method (lines 511-533):
  - Wraps KV-cache storage with section timing
  - Uses session.section("kv_cache_store", "prefill") context manager
  - Captures time to store keys and values from prefill
  - Accepts arbitrary store function with *args and **kwargs
  - Comprehensive docstring with usage example
- Added profile_prefill() convenience method (lines 535-576):
  - Wraps entire prefill forward pass with automatic section breakdown
  - Uses session.section("prefill_complete", "prefill") context manager
  - Resets LayerProfiler for fresh metrics capture
  - Runs model forward pass with return_dict=True
  - LayerProfiler hooks automatically capture per-layer and per-component metrics
  - Retrieves and logs layer timings after forward pass
  - Returns logits by default or full output if return_full_output=True
  - Provides convenience API for standard prefill profiling
  - Comprehensive docstring with usage examples
- All methods leverage existing section() context manager for automatic energy correlation
- Prefill metrics automatically stored in session.sections list
- Database integration already handled by existing _save_run_to_database() method
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-022 passes = true

### EP-023: InferencePipelineProfiler - Decode Phase - COMPLETED
- Implemented decode phase profiling helper methods in InferencePipelineProfiler
- Added profile_decode_token() method (lines 582-636):
  - Wraps single decode token generation with section timing
  - Creates unique section name per token: f"decode_token_{token_index}"
  - Resets LayerProfiler before each token for fresh per-token metrics
  - Uses session.section(section_name, "decode") context manager
  - Runs model forward pass and extracts next token logits
  - Updates model kwargs (past_key_values, etc.) for next iteration
  - Captures layer timings via LayerProfiler hooks per token
  - Returns tuple of (next_token_logits, updated_model_kwargs)
  - Comprehensive docstring with usage example
- Added profile_decode_embedding() method (lines 638-662):
  - Wraps token embedding lookup during decode with section timing
  - Uses session.section("embedding", "decode") context manager
  - Accepts arbitrary embedding function with *args and **kwargs
  - Returns embedding tensor
  - Comprehensive docstring with usage example
- Added profile_decode_position() method (lines 664-688):
  - Wraps position embedding during decode with section timing
  - Uses session.section("position", "decode") context manager
  - Accepts arbitrary position function with *args and **kwargs
  - Returns result with position embeddings
  - Comprehensive docstring with usage example
- Added profile_decode_layers() method (lines 690-716):
  - Wraps transformer layers during decode with section timing
  - Uses session.section("layers", "decode") context manager
  - LayerProfiler hooks automatically capture per-layer metrics
  - Returns output from transformer layers
  - Comprehensive docstring with usage example
- Added profile_decode_lm_head() method (lines 718-742):
  - Wraps LM head projection during decode with section timing
  - Uses session.section("lm_head", "decode") context manager
  - Returns vocabulary logits
  - Comprehensive docstring with usage example
- Added profile_decode_sampling() method (lines 744-770):
  - Wraps sampling operation (temperature, top_k, top_p, token selection)
  - Uses session.section("sampling", "decode") context manager
  - Returns selected token ID
  - Comprehensive docstring with usage example
- Added profile_decode_kv_cache_append() method (lines 772-796):
  - Wraps KV-cache append during decode with section timing
  - Uses session.section("kv_cache_append", "decode") context manager
  - Returns updated KV cache
  - Comprehensive docstring with usage example
- Added profile_decode_loop() convenience method (lines 798-896):
  - Wraps complete decode loop with automatic per-token profiling
  - Accepts max_new_tokens, temperature, top_p, top_k parameters
  - Resets LayerProfiler between tokens for fresh metrics
  - Creates section per token: f"token_{token_idx}"
  - Implements temperature scaling for sampling
  - Implements top_k filtering for sampling
  - Implements top_p (nucleus) filtering for sampling
  - Uses torch.multinomial for token sampling
  - Updates model kwargs (past_key_values) per iteration
  - Captures layer timings via hooks per token
  - Checks for EOS token (ID 2) to terminate early
  - Returns generated token IDs tensor
  - Comprehensive docstring with usage example showing integration with prefill
- All decode methods leverage existing section() context manager for automatic energy correlation
- Decode metrics automatically stored in session.sections list
- LayerProfiler reset between tokens ensures per-token granularity
- Database integration already handled by existing _save_run_to_database() method
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-023 passes = true

### EP-024: InferencePipelineProfiler - Post-Inference Phase - COMPLETED
- Implemented post-inference phase profiling helper methods in InferencePipelineProfiler
- Added profile_tensor_to_cpu() method (lines 902-927):
  - Wraps tensor.to('cpu') with section timing
  - Uses session.section("tensor_to_cpu", "post_inference") context manager
  - Captures time to move output tensors from device memory (GPU/ANE/MPS) to CPU
  - Returns CPU tensor for further processing
  - Comprehensive docstring with usage example
- Added profile_detokenization() method (lines 929-955):
  - Wraps tokenizer.decode() with section timing
  - Uses session.section("detokenization", "post_inference") context manager
  - Captures time to decode token IDs back to text
  - Uses skip_special_tokens=True for clean output
  - Returns decoded text string
  - Comprehensive docstring with usage example
- Added profile_cleanup() method (lines 957-986):
  - Wraps cleanup operations with section timing
  - Uses session.section("cleanup", "post_inference") context manager
  - Accepts arbitrary cleanup function with *args and **kwargs for flexibility
  - Captures time for cache clearing, memory release, or garbage collection
  - Returns result from cleanup function (if any)
  - Comprehensive docstring with usage example
- Added get_total_inference_energy() method (lines 988-1046):
  - Calculates total inference energy from all profiled sections
  - Aggregates energy consumption across all four phases:
    * Pre-inference (tokenization, tensor transfer, KV-cache init)
    * Prefill (prompt processing)
    * Decode (token generation)
    * Post-inference (detokenization, cleanup)
  - Returns comprehensive dictionary with:
    * total_energy_mj: Total energy consumption in millijoules
    * pre_inference_energy_mj: Energy for pre-inference phase
    * prefill_energy_mj: Energy for prefill phase
    * decode_energy_mj: Energy for decode phase
    * post_inference_energy_mj: Energy for post-inference phase
    * total_duration_ms: Total duration in milliseconds
    * avg_power_mw: Average power draw in milliwatts
  - Accumulates energy per phase from all sections
  - Handles missing energy values gracefully (None checks)
  - Calculates average power across entire inference
  - Comprehensive docstring with usage example
- All post-inference methods leverage existing section() context manager for automatic energy correlation
- Post-inference metrics automatically stored in session.sections list
- Database integration already handled by existing _save_run_to_database() method
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-024 passes = true

### EP-025: InferencePipelineProfiler - Data Aggregation - COMPLETED
- Implemented comprehensive data aggregation in InferencePipelineProfiler
- Added aggregate_profiling_data() method (lines 1048-1168):
  - Collects all profiling data from completed session into structured format
  - Step 1: Collects all power samples from PowerMonitor
    * Converts PowerSample objects to dictionaries
    * Includes timestamp, CPU/GPU/ANE/DRAM/total power
  - Step 2: Collects all section timings with energy calculations
    * Includes phase, section name, start/end times, duration
    * Includes energy (mJ), average power (mW), power sample count
  - Step 3: Collects layer metrics from LayerProfiler
    * Layer index, component name, duration
    * Activation statistics (mean, std, max, sparsity)
  - Step 4: Aggregates component metrics by component type
    * Calls _aggregate_component_metrics() helper
    * Groups by component name (q_proj, k_proj, etc.)
  - Step 5: Collects deep operation metrics if enabled
    * Calls _aggregate_deep_metrics() helper
    * Includes attention, MLP, and LayerNorm operation metrics
  - Step 6: Energy per section already calculated (done in section() context manager)
  - Step 7: Builds complete run data structure
    * run_metadata: run_id, timestamp, model, prompt, response, tags, etc.
    * power_samples: List of all power measurements
    * section_timings: List of all pipeline sections with energy
    * layer_metrics: Per-layer timing and activation statistics
    * component_metrics: Per-component aggregated metrics
    * deep_metrics: Operation-level metrics (if available)
    * energy_summary: Total and per-phase energy breakdown
  - Comprehensive logging throughout aggregation process
  - Returns complete dictionary with all profiling data
- Added _aggregate_component_metrics() helper method (lines 1170-1232):
  - Groups layer metrics by component name
  - Calculates total duration per component type
  - Calculates count of occurrences per component
  - Calculates average duration per occurrence
  - Calculates average activation statistics across occurrences
  - Returns dictionary mapping component name to aggregated metrics
- Added _aggregate_deep_metrics() helper method (lines 1234-1318):
  - Collects attention operation metrics from DeepAttentionProfiler
    * QK^T matmul, scale, mask, softmax, value matmul timings
    * Attention entropy, sparsity, max weights per head and averaged
  - Collects MLP operation metrics
    * Gate proj, up proj, gate*up mult, down proj timings
    * Activation kill ratios
  - Collects LayerNorm operation metrics
    * Mean, variance, normalization, scale/shift timings
    * Variance ratios (input/output)
  - Calculates summary statistics
    * Number of operations per type
    * Total time per operation type
    * Average attention entropy and MLP activation kill ratio
  - Returns dictionary with attention_ops, mlp_ops, layernorm_ops, and summary
- All EP-025 requirements fulfilled:
  ✓ Collect all power samples from PowerMonitor
  ✓ Collect all section timings
  ✓ Collect all token metrics with layer breakdowns
  ✓ Collect all component metrics
  ✓ Collect deep operation metrics if enabled
  ✓ Calculate energy per section (power * time)
  ✓ Build complete run data structure
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-025 passes = true

### EP-026: InferencePipelineProfiler - Database Save - COMPLETED
- Enhanced _save_run_to_database() method to save complete profiling run data to database
- Step 1: Create profiling_runs record (already implemented)
- Step 2: Batch insert power_samples (already implemented)
- Step 3: Insert pipeline_sections (already implemented)
- Step 4: Insert tokens with metrics
  - Extracts decode sections representing tokens
  - Parses token index from section name (e.g., "decode_token_0")
  - Calls database.add_token() with token_index, duration_ms, energy_mj, avg_power_mw
  - token_text field left as None (will be populated in future enhancements)
- Step 5: Batch insert layer_metrics
  - Collects all layer timings from LayerProfiler.get_timings()
  - Creates list of layer_metric_dicts with all fields
  - Calls database.add_layer_metrics() with batch insert
  - Currently saved at run level (token_id=None)
  - Future enhancement: associate with individual tokens for per-token granularity
- Step 6: Batch insert component_metrics
  - Aggregates layer timings by component name (q_proj, k_proj, etc.)
  - Calculates total_duration_ms, count, and averages for activation statistics
  - Creates component_metric_dicts with aggregated data
  - Calls database.add_component_metrics() with batch insert
  - Provides component-level summary across entire run
- Step 7: Batch insert deep_operation_metrics if present
  - Checks if deep profiling was enabled (profiling_depth == "deep")
  - Collects attention operation metrics from DeepAttentionProfiler
    * Includes qk_matmul_time, scale_time, mask_time, softmax_time, value_matmul_time
    * Includes attention_entropy, attention_sparsity, max_attention_weight
  - Collects MLP operation metrics
    * Includes gate_proj_time, up_proj_time, gate_up_mult_time, down_proj_time
    * Includes activation_kill_ratio
  - Collects LayerNorm operation metrics
    * Includes mean_time, variance_time, normalization_time, scale_shift_time
    * Includes variance_ratio
  - Calls database.add_deep_operation_metrics() with batch insert
  - All deep metrics saved with operation_type and operation_name for categorization
- Step 8: Return run_id for reference (implicitly via session.run_id)
- Enhanced logging to show comprehensive save statistics
  - Number of power samples saved
  - Number of sections saved
  - Number of tokens saved
  - Number of component types saved
- All database saves wrapped in comprehensive error handling
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-026 passes = true

### EP-027: Profiled Generate Endpoint - COMPLETED
- Created ProfiledGenerateRequest Pydantic model in backend/main.py (lines 1567-1573)
  - prompt: str - The input prompt for text generation
  - modelPath: str - Path to the model directory for inference
  - profilingDepth: str = "module" - Profiling granularity ("module" or "deep")
  - tags: Optional[str] = None - Optional tags for categorization
  - experimentName: Optional[str] = None - Optional experiment name for organization
  - config: InferenceConfig = InferenceConfig() - Inference parameters (temperature, top_k, etc.)
- Implemented POST /api/profiling/generate endpoint (lines 1576-1705)
  - Comprehensive profiled inference with full energy tracking
  - Validates model path exists before starting profiling
  - Checks powermetrics availability with helpful error message
  - Loads model and tokenizer with trust_remote_code=True support
  - Detects device (MPS for Apple Silicon, CUDA, or CPU)
  - Uses appropriate dtype (float16 for CUDA, float32 otherwise)
  - Initializes all profiling components:
    * PowerMonitor with 100ms sample interval
    * LayerProfiler for per-layer/per-component metrics
    * DeepAttentionProfiler for operation-level metrics (if profilingDepth='deep')
    * ProfileDatabase for storing all profiling data
  - Creates InferencePipelineProfiler orchestrator
  - Runs inference within profiler.run() context manager:
    * Pre-inference phase: tokenization, tensor transfer sections
    * Prefill phase: single forward pass for prompt processing
    * Post-inference phase: detokenization section
  - Automatically saves complete profiling data to database on completion
  - Proper cleanup: unpatch deep profiler, detach layer profiler
  - Returns run_id, response, and success message
  - Comprehensive error handling with detailed error messages
- Integration with existing profiling system:
  - Uses InferencePipelineProfiler.run() context manager for lifecycle
  - Uses session.section() for timing individual operations
  - Power samples automatically correlated with sections
  - All metrics saved to database automatically on context exit
- Profiling captured for entire inference pipeline:
  - Pre-inference: tokenization (encode), tensor transfer (to device)
  - Prefill: model.generate() first forward pass
  - Decode: model.generate() token-by-token generation (internal)
  - Post-inference: detokenization (decode)
- API response includes:
  - runId: Unique identifier for this profiling run (UUID4)
  - response: Generated text from the model
  - message: Success confirmation
- Error handling:
  - 404 if model path not found
  - 503 if powermetrics not available (with setup instructions)
  - 500 for any generation or profiling failures
- Verified Python syntax with py_compile (no errors)
- Verified TypeScript compilation with npm run build (successful)
- Updated PRD: EP-027 passes = true

### EP-028: Profiling Runs List Endpoint - COMPLETED
- Implemented GET /api/profiling/runs endpoint in backend/main.py (lines 1715-1832)
  - Accepts comprehensive query parameters for filtering:
    * model: Filter by model name
    * date_from: Filter runs from this timestamp (ISO format)
    * date_to: Filter runs up to this timestamp (ISO format)
    * tags: Filter by comma-separated tags (partial match)
    * experiment: Filter by experiment name
    * limit: Maximum number of results (1-1000, default 100)
    * offset: Number of results to skip for pagination (default 0)
    * sort_by: Sort by date (default), duration, or energy
  - Integrates with ProfileDatabase.get_runs() with all filter parameters
  - Adds summary metrics for each run:
    * Retrieves run summary from database
    * Calculates total_duration_ms from phase breakdown (sum across all phases)
    * Calculates total_energy_mj from phase breakdown (sum across all phases)
    * Includes input_tokens and output_tokens if available
  - Returns list with full run metadata plus calculated metrics:
    * run_id, timestamp, model_name, prompt, response
    * experiment_name, tags, profiling_depth, status
    * total_duration_ms, total_energy_mj
    * input_tokens, output_tokens
  - Implements sorting options:
    * date: Default sort by timestamp DESC (from database)
    * duration: Sort by total_duration_ms descending
    * energy: Sort by total_energy_mj descending
  - Returns response dictionary with:
    * runs: List of run objects with summary metrics
    * total: Count of returned runs
    * limit: Applied limit value
    * offset: Applied offset value
  - Comprehensive error handling with 500 status on failures
  - Logging for all errors with detailed messages
- Added logging import and logger setup to main.py:
  - import logging at top of file
  - logging.basicConfig(level=logging.INFO) configuration
  - logger = logging.getLogger(__name__) initialization
- Pagination support enables efficient browsing of large run histories
  - Standard limit/offset pattern for REST API pagination
  - Client can request pages by adjusting offset (e.g., offset=0, offset=100, offset=200)
- Filtering enables targeted queries:
  - Filter by model to compare different models
  - Filter by date range to analyze time periods
  - Filter by tags or experiment name for organized profiling campaigns
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-028 passes = true

### EP-029: Profiling Run Detail Endpoint - COMPLETED
- Implemented GET /api/profiling/run/{run_id} endpoint in backend/main.py (lines 1839-1930)
  - Retrieves complete profiling run data including all nested metrics
  - Validates run_id exists and returns 404 if not found
  - Connects to ProfileDatabase and queries all related tables
  - Returns comprehensive nested data structure:
    * run: Complete run metadata (model, prompt, response, timestamps, tags, etc.)
    * power_samples: All power samples ordered by timestamp
    * pipeline_sections: All section timings ordered by start time
    * tokens: All tokens with nested layer and component metrics
  - Implements full hierarchical data structure:
    * Each token includes array of layer metrics
    * Each layer includes array of component metrics
    * Each component includes array of deep operation metrics (if present)
  - Uses database.get_run() to fetch basic run metadata
  - Uses database.get_power_timeline() to fetch all power samples
  - Executes SQL query to fetch all pipeline_sections ordered by start_time_ms
  - Uses database.get_tokens() to fetch all tokens ordered by token_index
  - For each token:
    * Calls database.get_layer_metrics(token_id) to fetch layer metrics
    * For each layer:
      - Calls database.get_component_metrics(layer_metric_id) to fetch component metrics
      - For each component:
        * Executes SQL query to fetch deep_operation_metrics ordered by operation_name
        * Attaches deep_operations array to component dictionary
      - Attaches components array to layer dictionary
    * Attaches layers array to token dictionary
  - Returns complete JSON response with four top-level fields
  - Comprehensive error handling:
    * HTTPException for 404 when run not found
    * HTTPException with 500 status for database errors
    * Re-raises HTTPException to preserve error codes
    * Logs all errors with detailed messages
  - Proper resource management:
    * Closes database connection after query completion
    * try/except blocks protect against partial data retrieval
  - Supports both module and deep profiling depths:
    * Deep operation metrics included only if profiling_depth='deep'
    * Gracefully handles missing deep metrics (empty arrays)
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-029 passes = true

### EP-030: Profiling Run Summary Endpoint - COMPLETED
- Implemented GET /api/profiling/run/{run_id}/summary endpoint in backend/main.py (lines 1933-1992)
  - Retrieves aggregated summary statistics for a profiling run
  - Leverages ProfileDatabase.get_run_summary() method for efficient aggregation
  - Returns comprehensive summary metrics including:
    * Total duration and energy calculated from phase breakdown
    * Per-phase breakdown (pre_inference, prefill, decode, post_inference)
      - Each phase includes: total_duration_ms, total_energy_mj, avg_power_mw, section_count
    * Average metrics per layer (across all tokens)
      - Includes: layer_index, avg_duration_ms, avg_energy_mj, avg_power_mw, token_count
    * Average metrics per component (across all layers and tokens)
      - Includes: component_name, avg_duration_ms, avg_energy_mj, avg_power_mw
      - Includes: avg_activation_mean, avg_activation_std, avg_activation_max, avg_activation_sparsity
      - Includes: occurrence_count
      - Sorted by avg_energy_mj DESC to highlight most expensive components
    * Hottest components (top 10 by energy consumption)
      - Same structure as component_averages but limited to top 10
  - Calculates derived metrics:
    * total_duration_ms: Sum of all phase durations
    * total_energy_mj: Sum of all phase energies
    * avg_power_mw: (total_energy_mj / total_duration_ms) × 1000
    * tokens_per_second: (token_count / total_duration_ms) × 1000 (if token_count available)
  - Uses database.get_run_summary() which executes efficient SQL aggregations:
    * GROUP BY phase for phase breakdown
    * GROUP BY layer_index for layer averages with AVG() and COUNT()
    * GROUP BY component_name for component averages with AVG() and COUNT()
    * JOIN across layer_metrics, component_metrics, and tokens tables
  - Comprehensive error handling:
    * HTTPException for 404 when run not found
    * HTTPException with 500 status for database errors
    * Re-raises HTTPException to preserve error codes
    * Logs all errors with detailed messages
  - Proper resource management:
    * Closes database connection after query completion
    * try/except blocks protect against partial data retrieval
  - API response structure:
    * All run metadata fields from profiling_runs table
    * phase_breakdown: List of per-phase aggregated metrics
    * layer_averages: List of per-layer aggregated metrics
    * component_averages: List of per-component aggregated metrics
    * hottest_components: Top 10 most energy-intensive components
    * total_duration_ms: Calculated total duration
    * total_energy_mj: Calculated total energy
    * avg_power_mw: Calculated average power draw
    * tokens_per_second: Calculated throughput (if applicable)
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-030 passes = true

### EP-031: Profiling Pipeline Breakdown Endpoint - COMPLETED
- Implemented GET /api/profiling/run/{run_id}/pipeline endpoint in backend/main.py (lines 1995-2085)
  - Retrieves hierarchical pipeline section breakdown for a profiling run
  - Returns detailed phase > section structure with timing and energy data
  - Added get_pipeline_sections(run_id) method to ProfileDatabase class (database.py:793-809)
    * Queries pipeline_sections table ordered by start_time_ms
    * Returns list of section dictionaries with all fields
  - Calculates comprehensive metrics per section:
    * Duration percentage: (section_duration / total_duration) × 100
    * Energy percentage: (section_energy / total_energy) × 100
  - Groups sections hierarchically by phase (pre_inference, prefill, decode, post_inference)
  - Each phase includes:
    * phase: Phase identifier
    * sections: Array of sections within phase
    * total_duration_ms: Sum of all section durations in phase
    * total_energy_mj: Sum of all section energies in phase
    * avg_power_mw: Average power draw for phase
    * section_count: Number of sections in phase
    * duration_percentage: Phase percentage of total duration
    * energy_percentage: Phase percentage of total energy
  - Each section includes:
    * All fields from pipeline_sections table (id, phase, section_name, start/end times, duration, energy, avg_power)
    * duration_percentage: Section percentage of total duration
    * energy_percentage: Section percentage of total energy
  - Returns structured response:
    * run_id: Run identifier
    * total_duration_ms: Total duration across all sections
    * total_energy_mj: Total energy across all sections
    * phases: List of phase dictionaries with nested sections
  - Comprehensive error handling:
    * HTTPException for 404 when no pipeline data found
    * HTTPException with 500 status for database errors
    * Re-raises HTTPException to preserve error codes
    * Logs all errors with detailed messages
  - Proper resource management:
    * Closes database connection after query completion
    * try/except blocks protect against partial data retrieval
  - Enables detailed pipeline analysis:
    * Identify bottleneck phases and sections
    * Compare time vs energy consumption per section
    * Analyze percentage contribution of each operation
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-031 passes = true

### EP-032: Profiling Export Endpoint - COMPLETED
- Implemented GET /api/profiling/export/{run_id} endpoint in backend/main.py (lines 2092-2296)
  - Accepts format query parameter with validation: "json" or "csv" (default: "json")
  - Validates run_id exists and returns 404 if not found
- JSON export format implementation:
  - Retrieves complete nested data structure identical to detail endpoint
  - Includes run metadata, power_samples, pipeline_sections, and tokens
  - Tokens include nested layer_metrics with component_metrics and deep_operations
  - Uses json.dumps() with indent=2 for readable formatting
  - default=str parameter handles datetime and non-JSON-serializable types
  - Returns StreamingResponse with application/json content type
  - Content-Disposition header triggers browser download: profiling_run_{run_id}.json
- CSV export format implementation:
  - Flattened multi-section CSV format for spreadsheet analysis
  - Section 1: Run metadata as key-value pairs
  - Section 2: Power samples table with all measurement columns
  - Section 3: Pipeline sections table with timing and energy data
  - Section 4: Tokens table with token-level metrics
  - Section 5: Layer metrics summary with JOIN to tokens for context
  - Section 6: Component metrics summary with JOIN to layers and tokens
  - Uses csv.writer() to generate properly formatted CSV
  - Each section separated by blank lines for readability
  - Header rows included for each table section
  - Returns StreamingResponse with text/csv content type
  - Content-Disposition header triggers browser download: profiling_run_{run_id}.csv
- Proper HTTP response headers:
  - Content-Type: application/json for JSON format
  - Content-Type: text/csv for CSV format
  - Content-Disposition: attachment; filename="..." triggers download dialog
- Comprehensive error handling:
  - HTTPException for 404 when run not found
  - HTTPException with 500 status for export failures
  - Re-raises HTTPException to preserve error codes
  - Logs all errors with detailed messages
- Proper resource management:
  - Closes database connection in finally block
  - try/except blocks protect against partial export failures
- StreamingResponse implementation:
  - Uses io.BytesIO() to create in-memory file stream
  - Efficient for large exports without loading entire response in memory
  - Supports both JSON and CSV content with proper encoding (utf-8)
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-032 passes = true

### EP-033: Profiling Delete Endpoint - COMPLETED
- Implemented DELETE /api/profiling/run/{run_id} endpoint in backend/main.py (lines 2299-2354)
  - Accepts run_id path parameter to identify the profiling run to delete
  - Validates run_id exists and returns 404 if not found
- Comprehensive deletion functionality:
  - Connects to ProfileDatabase and checks if run exists
  - Uses database.delete_run(run_id) which performs cascade delete
  - Cascade delete removes all related records from all tables:
    * power_samples (all power measurements for this run)
    * pipeline_sections (all phase and section timings)
    * tokens (all generated tokens with metrics)
    * layer_metrics (all per-layer profiling data)
    * component_metrics (all per-component metrics)
    * deep_operation_metrics (all operation-level metrics if present)
  - CASCADE DELETE constraints defined in database schema ensure data integrity
  - Single delete_run() call handles all related record cleanup
- Returns success response with:
  - success: True (boolean flag for client confirmation)
  - message: Human-readable success message
  - run_id: Echo back the deleted run identifier
- Comprehensive error handling:
  - HTTPException with 404 status when run not found
  - HTTPException with 500 status for any deletion failures
  - Re-raises HTTPException to preserve proper error codes
  - Logs all errors with detailed messages for debugging
- Proper resource management:
  - Closes database connection in finally block
  - try/except blocks protect against partial deletion failures
  - Database connection closed even if errors occur
- Logging:
  - Info-level log on successful deletion
  - Error-level log with exception details on failures
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-033 passes = true

### EP-034: WebSocket Profiling Endpoint - Setup - COMPLETED
- Implemented /ws/profiling WebSocket endpoint in backend/main.py (lines 2437-2506)
  - Full-duplex WebSocket connection for real-time profiling data streaming
  - Accepts connections at ws://localhost:8000/ws/profiling
  - Generates unique client ID (UUID4) for each connection
  - Handles client connection lifecycle: connect -> stream -> disconnect
- Created ProfilingConnectionManager class (lines 2358-2417)
  - Manages multiple concurrent WebSocket connections
  - Maintains list of active_connections
  - Implements per-client message queues using asyncio.Queue()
  - Methods:
    * connect(websocket, client_id): Accept and register new connection
    * disconnect(websocket, client_id): Remove connection and cleanup queue
    * send_message(message, client_id): Send to specific client or broadcast
    * broadcast(message): Send message to all connected clients
  - Thread-safe queue-based architecture for reliable message delivery
  - Comprehensive logging for connection events
- Created ProfilingMessageType class (lines 2421-2430)
  - Defines message type enumeration for profiling events:
    * POWER_SAMPLE: Power measurement samples
    * SECTION_START: Pipeline section start events
    * SECTION_END: Pipeline section completion events
    * TOKEN_COMPLETE: Token generation completion events
    * LAYER_METRICS: Per-layer profiling metrics
    * COMPONENT_METRICS: Per-component profiling metrics
    * INFERENCE_COMPLETE: Inference completion summary
    * ERROR: Error messages
- Implemented _send_messages_to_client() background task (lines 2509-2536)
  - Runs concurrently with WebSocket receive loop
  - Pulls messages from client-specific queue
  - Sends messages as JSON via websocket.send_json()
  - Graceful error handling for send failures
  - Proper cancellation handling with asyncio.CancelledError
- Message format standardized as:
  {
    "type": "message_type",
    "timestamp": float,
    "data": {...}
  }
- WebSocket endpoint features:
  - Bi-directional communication (can receive client messages)
  - Handles WebSocketDisconnect exceptions gracefully
  - JSON parsing with error handling for invalid client messages
  - Proper cleanup in finally block (disconnect, cancel sender task)
  - Comprehensive error logging throughout lifecycle
- Global profiling_manager instance for application-wide access
- Ready for integration with InferencePipelineProfiler for streaming events
- Verified Python syntax with py_compile (no errors)
- Updated PRD: EP-034 passes = true

